/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @numba.jit()
/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @numba.jit()
/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @numba.jit()
/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @numba.jit()
2023-12-26 12:28:02.283392: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-12-26 12:28:02.354345: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-26 12:28:03.358080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:147] Using 4 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c19229 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 52eff5 and rejected config c19229 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_oversamples': 7,
  'power_iteration_normalizer': 'LU',
  'svd_solver': 'randomized',
})
Incumbent score ...
0.4956995821326782
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 430fad as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b2f81c and rejected config 430fad as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 2,
  'n_iter': 5,
  'n_oversamples': 11,
  'power_iteration_normalizer': 'LU',
})
Incumbent score ...
0.4956995821326782
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d3d156 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a648c2 and rejected config d3d156 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 7052d5 and rejected config a648c2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'batch_size': 33,
  'n_components': 2,
})
Incumbent score ...
0.49566393462199243
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cbf288 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 8924b7 and rejected config cbf288 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 77510f and rejected config 8924b7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'algorithm': 'deflation',
  'fun': 'exp',
  'n_components': 2,
  'whiten_solver': 'svd',
})
Incumbent score ...
0.5238377580742464
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2207a2 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 13aba1 and rejected config 2207a2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config cf7ed1 and rejected config 13aba1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config f571d2 and rejected config cf7ed1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config d24e32 and rejected config f571d2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 6a340e and rejected config d24e32 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.1067602081577483,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.022386683345473876,
})
Incumbent score ...
0.4959558865743242
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 53e5f5 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 9c951d and rejected config 53e5f5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 7a0a32 and rejected config 9c951d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config c479f9 and rejected config 7a0a32 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 07addb and rejected config c479f9 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 04a36b and rejected config 07addb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.18224326370376068,
  'batch_size': 2,
  'method': 'cd',
  'n_components': 2,
  'ridge_alpha': 0.05035022322199937,
})
Incumbent score ...
0.48093270293072543
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 409ec3 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 791352 and rejected config 409ec3 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config a32b8c and rejected config 791352 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5b61d4 and rejected config a32b8c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 652d3b and rejected config 5b61d4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'iterated_power': 5,
  'n_components': 4,
  'rotation': 'varimax',
  'svd_method': 'randomized',
})
Incumbent score ...
0.47010985708166597
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a6f4d5 and rejected config d953c7 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 41e4e6 and rejected config a6f4d5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.1118680096231401,
  'early_exaggeration': 22.63680201023817,
  'init': 'pca',
  'learning_rate': 871.9470801018178,
  'method': 'exact',
  'n_components': 2,
  'n_iter': 615,
  'n_iter_without_progress': 295,
  'perplexity': 38.27241361606866,
})
Incumbent score ...
0.23243069648742676
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 043649 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config 043649 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 79760d and rejected config 1e6abb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config dd64d8 and rejected config 79760d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'eigen_solver': 'dense',
  'n_components': 2,
  'n_neighbors': 6,
  'neighbors_algorithm': 'auto',
  'path_method': 'FW',
})
Incumbent score ...
0.4117295083402637
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 42d1dc as new incumbent because there are no incumbents yet.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config 2196e6 and rejected config 42d1dc as incumbent because it is not better than the incumbents on 3 instances:
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config 401156 and rejected config 2196e6 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config b02c72 and rejected config 401156 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'eigen_solver': 'auto',
  'method': 'modified',
  'n_components': 2,
  'n_neighbors': 7,
  'neighbors_algorithm': 'kd_tree',
})
Incumbent score ...
0.18702482768463924
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 670869 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 8f6286 and rejected config 670869 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 7a96f4 and rejected config 8f6286 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 772003 and rejected config 7a96f4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 792ad1 and rejected config 772003 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 2,
})
Incumbent score ...
0.5035328747672754
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c04d5b as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config d88084 and rejected config c04d5b as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'lobpcg',
  'n_components': 2,
})
Incumbent score ...
0.35650847492266635
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 67ac02 and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b98189 and rejected config 67ac02 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 4bb6a1 and rejected config b98189 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 90acf1 and rejected config 4bb6a1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'braycurtis',
  'min_dist': 0.13544706696593195,
  'n_components': 3,
  'n_neighbors': 5,
})
Incumbent score ...
0.4197174906730652
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
         optimized_method  ...                                          incumbent
0  Local_Linear_Embedding  ...  {'eigen_solver': 'auto', 'method': 'modified',...

[1 rows x 3 columns]
Local_Linear_Embedding
{'eigen_solver': 'auto', 'method': 'modified', 'n_components': 2, 'n_neighbors': 7, 'neighbors_algorithm': 'kd_tree'}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
Local_Linear_Embedding
Initiating Consensus Clustering...
Local_Linear_Embedding
Initiating Consensus Clustering...
Local_Linear_Embedding
Mean score from Consensus Clustering is...
0.18702482768463924
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 055ddd as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config c19229 and rejected config 055ddd as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e453d8 and rejected config c19229 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config bbd829 and rejected config e453d8 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_oversamples': 3,
  'power_iteration_normalizer': 'LU',
  'svd_solver': 'randomized',
})
Incumbent score ...
0.43912858558403123
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 33cdb6 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b2f81c and rejected config 33cdb6 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_iter': 5,
  'n_oversamples': 11,
  'power_iteration_normalizer': 'LU',
})
Incumbent score ...
0.43906942784170955
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config e2b0ff as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config f72013 and rejected config e2b0ff as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 00d776 and rejected config f72013 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 470f44 and rejected config 00d776 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1d588a and rejected config 470f44 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 5745cc and rejected config 1d588a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 69ed63 and rejected config 5745cc as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 44c605 and rejected config 69ed63 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 0fc50f and rejected config 44c605 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'batch_size': 92,
  'n_components': 2,
})
Incumbent score ...
0.44472602446156073
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2abf0c as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 8924b7 and rejected config 2abf0c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 65a0ac and rejected config 8924b7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'algorithm': 'parallel',
  'fun': 'exp',
  'n_components': 2,
  'whiten_solver': 'svd',
})
Incumbent score ...
0.4204681853562573
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 69482e as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b91dcc and rejected config 69482e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 801419 and rejected config b91dcc as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config fa4141 and rejected config 801419 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d5c228 and rejected config fa4141 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config a3a66a and rejected config d5c228 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config ffc2ee and rejected config a3a66a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.9966181587879072,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.05532042829686433,
})
Incumbent score ...
0.43805446097562073
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 415833 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config d88a9c and rejected config 415833 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5ee751 and rejected config d88a9c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 435ac7 and rejected config 5ee751 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 2cf5d5 and rejected config 435ac7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b3da48 and rejected config 2cf5d5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.9428409421257191,
  'batch_size': 2,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.06172769004266011,
})
Incumbent score ...
0.42896563138977517
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2f3968 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 11f01f and rejected config 2f3968 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 197785 and rejected config 11f01f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 708077 and rejected config 197785 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'iterated_power': 2,
  'n_components': 2,
  'rotation': 'varimax',
  'svd_method': 'lapack',
})
Incumbent score ...
0.4617808846524263
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a6f4d5 and rejected config d953c7 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config c2d483 and rejected config a6f4d5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config be3d09 and rejected config c2d483 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.7997621418908238,
  'early_exaggeration': 14.138102843426168,
  'init': 'pca',
  'learning_rate': 564.7475776063675,
  'method': 'exact',
  'n_components': 3,
  'n_iter': 258,
  'n_iter_without_progress': 202,
  'perplexity': 6.039517538548153,
})
Incumbent score ...
0.2391844391822815
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 5870b8 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 22cb0b and rejected config 5870b8 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config 22cb0b as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'n_components': 2,
  'n_neighbors': 11,
  'neighbors_algorithm': 'kd_tree',
  'path_method': 'FW',
})
Incumbent score ...
0.4308877253259795
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c05de1 as new incumbent because there are no incumbents yet.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config 6ba4bc and rejected config c05de1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config bdab2a and rejected config 6ba4bc as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config aed395 and rejected config bdab2a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 8a1037 and rejected config aed395 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'method': 'modified',
  'n_components': 2,
  'n_neighbors': 13,
  'neighbors_algorithm': 'kd_tree',
})
Incumbent score ...
0.11139466612621174
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c0cb5d as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 48c752 and rejected config c0cb5d as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config fb3930 and rejected config 48c752 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 87e7bf and rejected config fb3930 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 772003 and rejected config 87e7bf as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 3,
})
Incumbent score ...
0.5160198989731185
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config face95 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 514153 and rejected config face95 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 99da96 and rejected config 514153 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d88084 and rejected config 99da96 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config c04d5b and rejected config d88084 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'amg',
  'n_components': 2,
})
Incumbent score ...
0.22169284012036894
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'braycurtis',
  'min_dist': 0.6143590484932065,
  'n_components': 2,
  'n_neighbors': 25,
})
Incumbent score ...
0.4081500768661499
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
         optimized_method  ...                                          incumbent
0  Local_Linear_Embedding  ...  {'eigen_solver': 'auto', 'method': 'modified',...

[1 rows x 3 columns]
Local_Linear_Embedding
{'eigen_solver': 'auto', 'method': 'modified', 'n_components': 2, 'n_neighbors': 13, 'neighbors_algorithm': 'kd_tree'}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
Local_Linear_Embedding
Initiating Consensus Clustering...
Local_Linear_Embedding
Initiating Consensus Clustering...
Local_Linear_Embedding
Mean score from Consensus Clustering is...
0.11139466612621174
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 96abe8 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 6bdad4 and rejected config 96abe8 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b87e65 and rejected config 6bdad4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 8dfd22 and rejected config b87e65 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 62b134 and rejected config 8dfd22 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 2,
  'n_oversamples': 6,
  'power_iteration_normalizer': 'QR',
  'svd_solver': 'randomized',
})
Incumbent score ...
0.48923456426245804
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config a9d894 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config fba675 and rejected config a9d894 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 79cf66 and rejected config fba675 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 9f7264 and rejected config 79cf66 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b57576 and rejected config 9f7264 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5605f7 and rejected config b57576 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 2,
  'n_iter': 3,
  'n_oversamples': 3,
  'power_iteration_normalizer': 'OR',
})
Incumbent score ...
0.49423801538993917
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 1a1fb0 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 24fc12 and rejected config 1a1fb0 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config b6dc16 and rejected config 24fc12 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config a75b3f and rejected config b6dc16 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 45aa88 and rejected config a75b3f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config ad05ac and rejected config 45aa88 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 68ad39 and rejected config ad05ac as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 07055d and rejected config 68ad39 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'batch_size': 172,
  'n_components': 2,
})
Incumbent score ...
0.48697254517576605
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 892e55 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 8924b7 and rejected config 892e55 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'algorithm': 'deflation',
  'fun': 'cube',
  'n_components': 2,
  'whiten_solver': 'eigh',
})
Incumbent score ...
0.5770262514435482
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config acd3e1 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 9dc2f5 and rejected config acd3e1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 86a505 and rejected config 9dc2f5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 8b4d5a and rejected config 86a505 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config c2bd16 and rejected config 8b4d5a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d6d0f7 and rejected config c2bd16 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.5647513455608296,
  'method': 'cd',
  'n_components': 2,
  'ridge_alpha': 0.03977580599100344,
})
Incumbent score ...
0.5109136382922418
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 707b42 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 45ac4a and rejected config 707b42 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 742e3a and rejected config 45ac4a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config f9509d and rejected config 742e3a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.1606034901359242,
  'batch_size': 2,
  'method': 'lars',
  'n_components': 18,
  'ridge_alpha': 0.05534268034663627,
})
Incumbent score ...
0.6032341989272232
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config bfa5ed as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 183109 and rejected config bfa5ed as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config a70b30 and rejected config 183109 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 46c825 and rejected config a70b30 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config e58b3d and rejected config 46c825 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1c34ef and rejected config e58b3d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'iterated_power': 5,
  'n_components': 14,
  'rotation': 'varimax',
  'svd_method': 'randomized',
})
Incumbent score ...
0.6491351526643099
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 41e4e6 and rejected config d953c7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 026fe4 and rejected config 41e4e6 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 534466 and rejected config 026fe4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 49ce0c and rejected config 534466 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 28f528 and rejected config 49ce0c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.7498500395233131,
  'early_exaggeration': 43.987204666788315,
  'init': 'pca',
  'learning_rate': 857.2453089686849,
  'method': 'barnes_hut',
  'n_components': 2,
  'n_iter': 798,
  'n_iter_without_progress': 127,
  'perplexity': 28.446647279185818,
})
Incumbent score ...
0.4183081388473511
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 9461c6 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 2f65c2 and rejected config 9461c6 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config 2f65c2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 10e400 and rejected config 1e6abb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 4e2d23 and rejected config 10e400 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config cfec0f and rejected config 4e2d23 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 6cfb42 and rejected config cfec0f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'arpack',
  'n_components': 2,
  'n_neighbors': 6,
  'neighbors_algorithm': 'ball_tree',
  'path_method': 'auto',
})
Incumbent score ...
0.45924322063413814
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d7bf6f as new incumbent because there are no incumbents yet.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config 43867f and rejected config d7bf6f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1447a1 and rejected config 43867f as incumbent because it is not better than the incumbents on 3 instances:
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config a9d522 and rejected config 1447a1 as incumbent because it is not better than the incumbents on 3 instances:
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'method': 'modified',
  'n_components': 3,
  'n_neighbors': 37,
  'neighbors_algorithm': 'kd_tree',
})
Incumbent score ...
0.48869941628929525
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 46854e as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 163bb7 and rejected config 46854e as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 7bbd60 and rejected config 163bb7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 09b985 and rejected config 7bbd60 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 7a96f4 and rejected config 09b985 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 4,
})
Incumbent score ...
0.5546673783253555
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config bde81a as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 750a20 and rejected config bde81a as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config f5be5a and rejected config 750a20 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config f2d4e6 and rejected config f5be5a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 514153 and rejected config f2d4e6 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'rbf',
  'eigen_solver': 'amg',
  'n_components': 2,
})
Incumbent score ...
0.0030898749719131535
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 2cde07 and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 16b403 and rejected config 2cde07 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 0b6a06 and rejected config 16b403 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config ce0332 and rejected config 0b6a06 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config aa77b8 and rejected config ce0332 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 17bbcc and rejected config aa77b8 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config c7669a and rejected config 17bbcc as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 269059 and rejected config c7669a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'braycurtis',
  'min_dist': 0.05533994406099375,
  'n_components': 3,
  'n_neighbors': 63,
})
Incumbent score ...
0.21966004371643066
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
     optimized_method  ...                                          incumbent
0  Spectral_Embedding  ...  {'affinity': 'rbf', 'eigen_solver': 'amg', 'n_...

[1 rows x 3 columns]
Spectral_Embedding
{'affinity': 'rbf', 'eigen_solver': 'amg', 'n_components': 2}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
Spectral_Embedding
Initiating Consensus Clustering...
Spectral_Embedding
Initiating Consensus Clustering...
Spectral_Embedding
Mean score from Consensus Clustering is...
0.0030898749719131535
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config e27b78 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config c19229 and rejected config e27b78 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config f9e50c and rejected config c19229 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 8bde56 and rejected config f9e50c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b87e65 and rejected config 8bde56 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config c67b1f and rejected config b87e65 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_oversamples': 4,
  'power_iteration_normalizer': 'QR',
  'svd_solver': 'randomized',
})
Incumbent score ...
0.21226016498277944
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config ac1c75 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b2f81c and rejected config ac1c75 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config c8c64e and rejected config b2f81c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 01fc3b and rejected config c8c64e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config d0a999 and rejected config 01fc3b as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 75de97 and rejected config d0a999 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_iter': 4,
  'n_oversamples': 3,
  'power_iteration_normalizer': 'LU',
})
Incumbent score ...
0.21226016741098974
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config e3b537 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a0cdf5 and rejected config e3b537 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 133379 and rejected config a0cdf5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 545c51 and rejected config 133379 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5da7ae and rejected config 545c51 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config f36dab and rejected config 5da7ae as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'batch_size': 59,
  'n_components': 2,
})
Incumbent score ...
0.21155903144675903
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cbf288 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 65a0ac and rejected config cbf288 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config ac5cb1 and rejected config 65a0ac as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'algorithm': 'parallel',
  'fun': 'cube',
  'n_components': 2,
  'whiten_solver': 'svd',
})
Incumbent score ...
0.48487438088517587
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2207a2 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 1cef88 and rejected config 2207a2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 315698 and rejected config 1cef88 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config aad140 and rejected config 315698 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 2f19e1 and rejected config aad140 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config c5e17e and rejected config 2f19e1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 9f704a and rejected config c5e17e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.995015208213021,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.05392189734974943,
})
Incumbent score ...
0.2035123852291436
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 45485e as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 216c97 and rejected config 45485e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b7fd4a and rejected config 216c97 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 4c7430 and rejected config b7fd4a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 768b34 and rejected config 4c7430 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 6aa534 and rejected config 768b34 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config f2c11a and rejected config 6aa534 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.8054896743081276,
  'batch_size': 2,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.0789677360030881,
})
Incumbent score ...
0.20609760884919848
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 0426de as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 11f01f and rejected config 0426de as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 24001d and rejected config 11f01f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d61ecb and rejected config 24001d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'iterated_power': 3,
  'n_components': 10,
  'rotation': 'varimax',
  'svd_method': 'randomized',
})
Incumbent score ...
0.3059407734461621
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b8bc2c and rejected config d953c7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 6d0dd9 and rejected config b8bc2c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.3469197424866878,
  'early_exaggeration': 30.609504888986248,
  'init': 'pca',
  'learning_rate': 267.84994253898645,
  'method': 'exact',
  'n_components': 2,
  'n_iter': 912,
  'n_iter_without_progress': 497,
  'perplexity': 42.016400612700494,
})
Incumbent score ...
0.009699761867523193
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config b7e231 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 5d92b2 and rejected config b7e231 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config 5d92b2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 3c2b06 and rejected config 1e6abb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 680ca5 and rejected config 3c2b06 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 237873 and rejected config 680ca5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 6ade3c and rejected config 237873 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'arpack',
  'n_components': 2,
  'n_neighbors': 15,
  'neighbors_algorithm': 'ball_tree',
  'path_method': 'FW',
})
Incumbent score ...
0.14052659865108297
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d6aa9d as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'eigen_solver': 'auto',
  'method': 'modified',
  'n_components': 2,
  'n_neighbors': 12,
  'neighbors_algorithm': 'ball_tree',
})
Incumbent score ...
0.4339361418065638
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c6cb9d as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 09b985 and rejected config c6cb9d as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config fb3930 and rejected config 09b985 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 8f6286 and rejected config fb3930 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 772003 and rejected config 8f6286 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 3,
})
Incumbent score ...
0.2810429666537998
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c04d5b as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'amg',
  'n_components': 2,
})
Incumbent score ...
0.42298049957966466
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 67ac02 and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e4b227 and rejected config 67ac02 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5eeb16 and rejected config e4b227 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 8fa125 and rejected config 5eeb16 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 46ae6d and rejected config 8fa125 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 6f6319 and rejected config 46ae6d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 815c93 and rejected config 6f6319 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'minkowski',
  'min_dist': 0.09347813843558136,
  'n_components': 3,
  'n_neighbors': 69,
})
Incumbent score ...
0.06804633140563965
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
  optimized_method   score                                          incumbent
0            t_SNE  0.0097  {'angle': 0.3469197424866878, 'early_exaggerat...
t_SNE
{'angle': 0.3469197424866878, 'early_exaggeration': 30.609504888986248, 'init': 'pca', 'learning_rate': 267.84994253898645, 'method': 'exact', 'n_components': 2, 'n_iter': 912, 'n_iter_without_progress': 497, 'perplexity': 42.016400612700494}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
t_SNE
Initiating Consensus Clustering...
t_SNE
Initiating Consensus Clustering...
t_SNE
Mean score from Consensus Clustering is...
0.009699761867523193
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config e27b78 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config c19229 and rejected config e27b78 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 0aeb74 and rejected config c19229 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 0ea502 and rejected config 0aeb74 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_oversamples': 4,
  'power_iteration_normalizer': 'auto',
  'svd_solver': 'randomized',
})
Incumbent score ...
0.33764454409908795
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config ac1c75 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b2f81c and rejected config ac1c75 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 988a22 and rejected config b2f81c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 047c6a and rejected config 988a22 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_iter': 7,
  'n_oversamples': 11,
  'power_iteration_normalizer': 'LU',
})
Incumbent score ...
0.33764453963743446
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config e3b537 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a0cdf5 and rejected config e3b537 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 133379 and rejected config a0cdf5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config c67a83 and rejected config 133379 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'batch_size': 76,
  'n_components': 2,
})
Incumbent score ...
0.3330857505657623
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cbf288 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 65a0ac and rejected config cbf288 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'algorithm': 'parallel',
  'fun': 'exp',
  'n_components': 2,
  'whiten_solver': 'svd',
})
Incumbent score ...
0.48114167760453497
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2207a2 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a660f1 and rejected config 2207a2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config a87edf and rejected config a660f1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config a8209a and rejected config a87edf as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 5b0bef and rejected config a8209a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config f312ff and rejected config 5b0bef as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config a4f57d and rejected config f312ff as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 0af651 and rejected config a4f57d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 24e29d and rejected config 0af651 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.8255745901414772,
  'method': 'cd',
  'n_components': 2,
  'ridge_alpha': 0.09275343523702062,
})
Incumbent score ...
0.33606138360923765
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 45485e as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 7ce838 and rejected config 45485e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config cbfab9 and rejected config 7ce838 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 800779 and rejected config cbfab9 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config b8fe39 and rejected config 800779 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 173997 and rejected config b8fe39 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.8730823576670533,
  'batch_size': 5,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.09352909724492851,
})
Incumbent score ...
0.33820681162486577
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 0426de as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 11f01f and rejected config 0426de as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 24001d and rejected config 11f01f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 791352 and rejected config 24001d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b6397f and rejected config 791352 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'iterated_power': 3,
  'n_components': 2,
  'rotation': 'quartimax',
  'svd_method': 'randomized',
})
Incumbent score ...
0.4172930104848198
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 990661 and rejected config d953c7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 6aee77 and rejected config 990661 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.46583295391203317,
  'early_exaggeration': 12.211505418564705,
  'init': 'pca',
  'learning_rate': 621.9519007619749,
  'method': 'exact',
  'n_components': 3,
  'n_iter': 512,
  'n_iter_without_progress': 277,
  'perplexity': 6.183882684517492,
})
Incumbent score ...
0.15805387496948242
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config b7e231 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 5d92b2 and rejected config b7e231 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config 5d92b2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 265b11 and rejected config 1e6abb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 2a130e and rejected config 265b11 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'dense',
  'n_components': 2,
  'n_neighbors': 5,
  'neighbors_algorithm': 'auto',
  'path_method': 'auto',
})
Incumbent score ...
0.3335449319040882
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d6aa9d as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'eigen_solver': 'auto',
  'method': 'modified',
  'n_components': 2,
  'n_neighbors': 12,
  'neighbors_algorithm': 'ball_tree',
})
Incumbent score ...
0.21784290080595237
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c6cb9d as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 61f3dc and rejected config c6cb9d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config fb3930 and rejected config 61f3dc as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 8f6286 and rejected config fb3930 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 5,
})
Incumbent score ...
0.4144793526465186
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c04d5b as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'amg',
  'n_components': 2,
})
Incumbent score ...
0.1589203675605506
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 7c7b9a and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 2189e8 and rejected config 7c7b9a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 7d58e2 and rejected config 2189e8 as incumbent because it is not better than the incumbents on 3 instances:
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config c32f85 and rejected config 7d58e2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 74da5c and rejected config c32f85 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'wminkowski',
  'min_dist': 0.40354456831184066,
  'n_components': 3,
  'n_neighbors': 17,
})
Incumbent score ...
0.24623000621795654
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
  optimized_method     score                                          incumbent
0            t_SNE  0.158054  {'angle': 0.46583295391203317, 'early_exaggera...
t_SNE
{'angle': 0.46583295391203317, 'early_exaggeration': 12.211505418564705, 'init': 'pca', 'learning_rate': 621.9519007619749, 'method': 'exact', 'n_components': 3, 'n_iter': 512, 'n_iter_without_progress': 277, 'perplexity': 6.183882684517492}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
t_SNE
Initiating Consensus Clustering...
t_SNE
Initiating Consensus Clustering...
t_SNE
Mean score from Consensus Clustering is...
0.15805387496948242
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 4 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c19229 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 52eff5 and rejected config c19229 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 8dfd22 and rejected config 52eff5 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_oversamples': 9,
  'power_iteration_normalizer': 'QR',
  'svd_solver': 'randomized',
})
Incumbent score ...
0.6280936009623171
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 430fad as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b2f81c and rejected config 430fad as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 2,
  'n_iter': 5,
  'n_oversamples': 11,
  'power_iteration_normalizer': 'LU',
})
Incumbent score ...
0.6280936009623175
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 9d6cc0 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 286f40 and rejected config 9d6cc0 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 73ceac and rejected config 286f40 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'batch_size': 15,
  'n_components': 2,
})
Incumbent score ...
0.6219440840412734
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cbf288 as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'algorithm': 'parallel',
  'fun': 'exp',
  'n_components': 2,
  'whiten_solver': 'eigh',
})
Incumbent score ...
0.6192230030149725
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2207a2 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config ea96b3 and rejected config 2207a2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 2d578c and rejected config ea96b3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config a8efcc and rejected config 2d578c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 2aeee4 and rejected config a8efcc as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 78fe93 and rejected config 2aeee4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d49026 and rejected config 78fe93 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 9b5d55 and rejected config d49026 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config cd9e31 and rejected config 9b5d55 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config df6995 and rejected config cd9e31 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config ed86b6 and rejected config df6995 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.9038584553653729,
  'method': 'cd',
  'n_components': 2,
  'ridge_alpha': 0.06894490184841442,
})
Incumbent score ...
0.6239377263274053
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 53e5f5 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 32a079 and rejected config 53e5f5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 76c304 and rejected config 32a079 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1714ea and rejected config 76c304 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5a7b79 and rejected config 1714ea as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config dc85af and rejected config 5a7b79 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.4083614181868376,
  'batch_size': 2,
  'method': 'cd',
  'n_components': 2,
  'ridge_alpha': 0.06208049023597204,
})
Incumbent score ...
0.4456677198760245
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 409ec3 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a9ed04 and rejected config 409ec3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config db7f75 and rejected config a9ed04 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'iterated_power': 3,
  'n_components': 3,
  'rotation': 'quartimax',
  'svd_method': 'randomized',
})
Incumbent score ...
0.42804473624252315
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 026fe4 and rejected config d953c7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e43ae3 and rejected config 026fe4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 67732a and rejected config e43ae3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.1980463202262227,
  'early_exaggeration': 22.63680201023817,
  'init': 'pca',
  'learning_rate': 930.3532088013193,
  'method': 'barnes_hut',
  'n_components': 2,
  'n_iter': 769,
  'n_iter_without_progress': 287,
  'perplexity': 38.27241361606866,
})
Incumbent score ...
0.41041624546051025
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 043649 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 019650 and rejected config 043649 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config 019650 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 110238 and rejected config 1e6abb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config c1851b and rejected config 110238 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'dense',
  'n_components': 2,
  'n_neighbors': 11,
  'neighbors_algorithm': 'kd_tree',
  'path_method': 'D',
})
Incumbent score ...
0.3963047194243611
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2d4953 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b33007 and rejected config 2d4953 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config fcd9d5 and rejected config b33007 as incumbent because it is not better than the incumbents on 3 instances:
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 356ca5 and rejected config fcd9d5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'dense',
  'method': 'modified',
  'n_components': 3,
  'n_neighbors': 3,
  'neighbors_algorithm': 'kd_tree',
})
Incumbent score ...
0.004412796514715156
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 670869 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 8f6286 and rejected config 670869 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 792ad1 and rejected config 8f6286 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 2,
})
Incumbent score ...
0.675507473833626
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c04d5b as new incumbent because there are no incumbents yet.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'amg',
  'n_components': 2,
})
Incumbent score ...
0.5983210884612127
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config 6c6b0c and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5bee61 and rejected config 6c6b0c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 9eca80 and rejected config 5bee61 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'braycurtis',
  'min_dist': 0.6047150488887524,
  'n_components': 2,
  'n_neighbors': 21,
})
Incumbent score ...
0.4615774154663086
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
         optimized_method  ...                                          incumbent
0  Local_Linear_Embedding  ...  {'eigen_solver': 'dense', 'method': 'modified'...

[1 rows x 3 columns]
Local_Linear_Embedding
{'eigen_solver': 'dense', 'method': 'modified', 'n_components': 3, 'n_neighbors': 3, 'neighbors_algorithm': 'kd_tree'}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
Local_Linear_Embedding
Initiating Consensus Clustering...
Local_Linear_Embedding
Initiating Consensus Clustering...
Local_Linear_Embedding
Mean score from Consensus Clustering is...
0.004412796514715156
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config f6d977 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config bace80 and rejected config f6d977 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 5dc2ed and rejected config bace80 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b0015e and rejected config 5dc2ed as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 829ed4 and rejected config b0015e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 2c1717 and rejected config 829ed4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 71bc86 and rejected config 2c1717 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 3,
  'svd_solver': 'auto',
})
Incumbent score ...
1.314400108756759e-31
Starting runs for the following method: NMF_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:515] Added config 73bc4a as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.0
Converged at iteration 3
violation: 1.0
violation: 0.0
Converged at iteration 3
[INFO][abstract_intensifier.py:590] Added config 15f738 and rejected config 73bc4a as incumbent because it is not better than the incumbents on 2 instances:
violation: 1.0
violation: 0.0
Converged at iteration 3
violation: 1.0
violation: 0.0519989032763485
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.05199594693568554
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.051990275207004964
violation: 0.0
Converged at iteration 4
[INFO][abstract_intensifier.py:590] Added config 3487c8 and rejected config 15f738 as incumbent because it is not better than the incumbents on 3 instances:
Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
violation: 1.0
violation: 0.09827217537358661
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.09826568816663862
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.09828068075337681
violation: 0.0
Converged at iteration 4
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.14168052713438933
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.1417557139898969
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.14175462214437337
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.09488687096205185
violation: 0.012188582237581342
violation: 0.001979701853895357
violation: 0.00033618278824769864
violation: 5.8865014276774193e-05
Converged at iteration 7
violation: 1.0
violation: 0.0948975899439395
violation: 0.012189850582298118
violation: 0.0019798982034137692
violation: 0.00033621449468620616
violation: 5.8870305590834786e-05
Converged at iteration 7
violation: 1.0
violation: 0.09491271981163453
violation: 0.012191613850252999
violation: 0.001980186852521405
violation: 0.000336263926584091
violation: 5.887902798434803e-05
Converged at iteration 7
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:590] Added config db7bdf and rejected config 3487c8 as incumbent because it is not better than the incumbents on 3 instances:
violation: 1.0
violation: 0.001146730831373318
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.001146730831373318
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.001146730831373318
violation: 0.0
Converged at iteration 4
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.27731895770980436
violation: 0.1206716110541346
violation: 0.0013212039993907004
violation: 0.0
Converged at iteration 6
violation: 1.0
violation: 0.27731895770980425
violation: 0.12067161105413457
violation: 0.0013212039993907014
violation: 0.0
Converged at iteration 6
violation: 1.0
violation: 0.2773189577098043
violation: 0.12067161105413456
violation: 0.0013212039993906995
violation: 0.0
Converged at iteration 6
Epoch 10 reached after 0.001 seconds, error: 18.245964
Epoch 20 reached after 0.002 seconds, error: 17.995939
Epoch 30 reached after 0.004 seconds, error: 17.752477
Epoch 40 reached after 0.005 seconds, error: 17.752189
Epoch 10 reached after 0.002 seconds, error: 18.031703
Epoch 20 reached after 0.003 seconds, error: 17.842838
Epoch 30 reached after 0.004 seconds, error: 17.752201
Epoch 40 reached after 0.006 seconds, error: 17.752189
Epoch 10 reached after 0.001 seconds, error: 17.953132
Epoch 20 reached after 0.003 seconds, error: 17.816371
Epoch 30 reached after 0.005 seconds, error: 17.752184
Epoch 40 reached after 0.006 seconds, error: 17.752189
Epoch 10 reached after 0.001 seconds, error: 11.543331
Epoch 10 reached after 0.001 seconds, error: 11.543331
Epoch 10 reached after 0.001 seconds, error: 11.543331
violation: 1.0
violation: 0.45812257750682067
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.4581225775068208
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.45812257750682117
violation: 0.0
Converged at iteration 4
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha_W': 0.017273878478400173,
  'beta_loss': 'frobenius',
  'init': 'nndsvd',
  'l1_ratio': 0.5941561837434165,
  'n_components': 6,
  'solver': 'mu',
  'verbose': 0,
})
Incumbent score ...
0.0010192375820658943
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 3bf718 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 25da49 and rejected config 3bf718 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 16,
  'n_iter': 4,
  'n_oversamples': 8,
  'power_iteration_normalizer': 'OR',
})
Incumbent score ...
1.9629931673276715e-31
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cee25a as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 3a11ef and rejected config cee25a as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 277ab5 and rejected config 3a11ef as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'batch_size': 117,
  'n_components': 3,
})
Incumbent score ...
1.4000997114376702e-31
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2abf0c as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[INFO][abstract_intensifier.py:590] Added config 61be56 and rejected config 2abf0c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 131, in svd
    raise LinAlgError("SVD did not converge")
numpy.linalg.LinAlgError: SVD did not converge


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 131, in svd
    raise LinAlgError("SVD did not converge")
numpy.linalg.LinAlgError: SVD did not converge


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 131, in svd
    raise LinAlgError("SVD did not converge")
numpy.linalg.LinAlgError: SVD did not converge


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'algorithm': 'deflation',
  'fun': 'cube',
  'n_components': 3,
  'whiten_solver': 'eigh',
})
Incumbent score ...
2.621293370574729e-31
Starting runs for the following method: MiniBatch_NMF
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config e0ce77 as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:590] Added config 22397a and rejected config e0ce77 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 9eac0f and rejected config 22397a as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:590] Added config d70614 and rejected config 9eac0f as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:590] Added config 5ec678 and rejected config d70614 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha_W': 0.048904189505328266,
  'batch_size': 160,
  'beta_loss': 'kullback-leibler',
  'init': 'nndsvd',
  'l1_ratio': 0.16164330980367134,
  'n_components': 5,
})
Incumbent score ...
0.014361632906930492
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 69482e as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 86c040 and rejected config 69482e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 4a509c and rejected config 86c040 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 54e346 and rejected config 4a509c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 0cccdb and rejected config 54e346 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config a6844f and rejected config 0cccdb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config cc9cad and rejected config a6844f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e2d949 and rejected config cc9cad as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.9838387071212964,
  'method': 'cd',
  'n_components': 18,
  'ridge_alpha': 0.010742168952322457,
})
Incumbent score ...
1.0169776733125e-05
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config bbef6b as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config dff6d1 and rejected config bbef6b as incumbent because it is not better than the incumbents on 2 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.9592367018572986,
  'batch_size': 3,
  'method': 'cd',
  'n_components': 15,
  'ridge_alpha': 0.010323922336101533,
})
Incumbent score ...
1.855416962482177e-05
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
  optimized_method         score                                  incumbent
0      PCA_sklearn  1.314400e-31  {'n_components': 3, 'svd_solver': 'auto'}
PCA_sklearn
{'n_components': 3, 'svd_solver': 'auto'}
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config f6d977 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config bace80 and rejected config f6d977 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 5dc2ed and rejected config bace80 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b0015e and rejected config 5dc2ed as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 829ed4 and rejected config b0015e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 2c1717 and rejected config 829ed4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 71bc86 and rejected config 2c1717 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 3,
  'svd_solver': 'auto',
})
Incumbent score ...
1.314400108756759e-31
Starting runs for the following method: NMF_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:515] Added config 73bc4a as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.0
Converged at iteration 3
violation: 1.0
violation: 0.0
Converged at iteration 3
[INFO][abstract_intensifier.py:590] Added config 15f738 and rejected config 73bc4a as incumbent because it is not better than the incumbents on 2 instances:
violation: 1.0
violation: 0.0
Converged at iteration 3
violation: 1.0
violation: 0.05198763086992133
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.0519997844303425
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.05198401925405139
violation: 0.0
Converged at iteration 4
[INFO][abstract_intensifier.py:590] Added config 3487c8 and rejected config 15f738 as incumbent because it is not better than the incumbents on 3 instances:
Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
violation: 1.0
violation: 0.09826624625447108
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.09828762939053934
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.09825838472111711
violation: 0.0
Converged at iteration 4
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.14170848390316254
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.1417385718329725
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.14167469285135062
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.09492100629444308
violation: 0.012192674659787742
violation: 0.001980365623251363
violation: 0.00033629540009911044
violation: 5.8884716747538105e-05
Converged at iteration 7
violation: 1.0
violation: 0.09489572594095104
violation: 0.012189505121522006
violation: 0.00197985121509603
violation: 0.00033620809634350013
violation: 5.8869437621148177e-05
Converged at iteration 7
violation: 1.0
violation: 0.09483798526576379
violation: 0.012182163892984365
violation: 0.001978655288826213
violation: 0.0003360043897743925
violation: 5.8833669713402164e-05
Converged at iteration 7
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:590] Added config db7bdf and rejected config 3487c8 as incumbent because it is not better than the incumbents on 3 instances:
violation: 1.0
violation: 0.0011467308313733177
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.0011467308313733175
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.001146730831373318
violation: 0.0
Converged at iteration 4
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.27731895770980425
violation: 0.12067161105413453
violation: 0.0013212039993906997
violation: 0.0
Converged at iteration 6
violation: 1.0
violation: 0.27731895770980425
violation: 0.12067161105413453
violation: 0.0013212039993906997
violation: 0.0
Converged at iteration 6
violation: 1.0
violation: 0.27731895770980414
violation: 0.12067161105413446
violation: 0.0013212039993906993
violation: 0.0
Converged at iteration 6
Epoch 10 reached after 0.001 seconds, error: 18.103775
Epoch 20 reached after 0.002 seconds, error: 17.756538
Epoch 30 reached after 0.003 seconds, error: 17.752189
Epoch 40 reached after 0.004 seconds, error: 17.752189
Epoch 10 reached after 0.001 seconds, error: 17.963008
Epoch 20 reached after 0.002 seconds, error: 17.752173
Epoch 30 reached after 0.003 seconds, error: 17.752189
Epoch 10 reached after 0.001 seconds, error: 17.756854
Epoch 20 reached after 0.002 seconds, error: 17.752195
Epoch 30 reached after 0.003 seconds, error: 17.752189
Epoch 10 reached after 0.001 seconds, error: 11.543331
Epoch 10 reached after 0.001 seconds, error: 11.543331
Epoch 10 reached after 0.001 seconds, error: 11.543331
violation: 1.0
violation: 0.45812257750682117
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.45812257750682084
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.45812257750682106
violation: 0.0
Converged at iteration 4
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha_W': 0.017273878478400173,
  'beta_loss': 'frobenius',
  'init': 'nndsvd',
  'l1_ratio': 0.5941561837434165,
  'n_components': 6,
  'solver': 'mu',
  'verbose': 0,
})
Incumbent score ...
0.0010192375820658895
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 3bf718 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 25da49 and rejected config 3bf718 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 941304 and rejected config 25da49 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 14,
  'n_iter': 4,
  'n_oversamples': 10,
  'power_iteration_normalizer': 'OR',
})
Incumbent score ...
6.526648738748862e-32
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cee25a as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 3a11ef and rejected config cee25a as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 277ab5 and rejected config 3a11ef as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'batch_size': 117,
  'n_components': 3,
})
Incumbent score ...
1.4000997114376702e-31
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2abf0c as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[INFO][abstract_intensifier.py:590] Added config 61be56 and rejected config 2abf0c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 131, in svd
    raise LinAlgError("SVD did not converge")
numpy.linalg.LinAlgError: SVD did not converge


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 131, in svd
    raise LinAlgError("SVD did not converge")
numpy.linalg.LinAlgError: SVD did not converge


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 131, in svd
    raise LinAlgError("SVD did not converge")
numpy.linalg.LinAlgError: SVD did not converge


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'algorithm': 'deflation',
  'fun': 'cube',
  'n_components': 3,
  'whiten_solver': 'eigh',
})
Incumbent score ...
2.3243329484963642e-30
Starting runs for the following method: MiniBatch_NMF
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config e0ce77 as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:590] Added config 22397a and rejected config e0ce77 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 9eac0f and rejected config 22397a as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:590] Added config d70614 and rejected config 9eac0f as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:590] Added config 5ec678 and rejected config d70614 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha_W': 0.048904189505328266,
  'batch_size': 160,
  'beta_loss': 'kullback-leibler',
  'init': 'nndsvd',
  'l1_ratio': 0.16164330980367134,
  'n_components': 5,
})
Incumbent score ...
0.014361632906930485
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 69482e as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b33785 and rejected config 69482e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 0d3f00 and rejected config b33785 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 792a37 and rejected config 0d3f00 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config cc9cad and rejected config 792a37 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 2f3418 and rejected config cc9cad as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 32e64d and rejected config 2f3418 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.29133517966328615,
  'method': 'cd',
  'n_components': 14,
  'ridge_alpha': 0.014218987350317007,
})
Incumbent score ...
4.589327058031935e-05
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config bbef6b as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config dff6d1 and rejected config bbef6b as incumbent because it is not better than the incumbents on 2 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.9592367018572986,
  'batch_size': 3,
  'method': 'cd',
  'n_components': 15,
  'ridge_alpha': 0.010323922336101533,
})
Incumbent score ...
8.352960756883132e-06
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
  optimized_method  ...                                          incumbent
0    Truncated_SVD  ...  {'n_components': 14, 'n_iter': 4, 'n_oversampl...

[1 rows x 3 columns]
Truncated_SVD
{'n_components': 14, 'n_iter': 4, 'n_oversamples': 10, 'power_iteration_normalizer': 'OR'}
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config f6d977 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 0efa8b and rejected config f6d977 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config c19229 and rejected config 0efa8b as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b28770 and rejected config c19229 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 1ac906 and rejected config b28770 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_oversamples': 6,
  'power_iteration_normalizer': 'auto',
  'svd_solver': 'randomized',
})
Incumbent score ...
0.5206964567875603
Starting runs for the following method: NMF_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:515] Added config 73bc4a as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.0
Converged at iteration 3
violation: 1.0
violation: 0.0
Converged at iteration 3
[INFO][abstract_intensifier.py:590] Added config 15f738 and rejected config 73bc4a as incumbent because it is not better than the incumbents on 2 instances:
violation: 1.0
violation: 0.0
Converged at iteration 3
violation: 1.0
violation: 0.05199313956865778
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.05198593472736303
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.05199594805537197
violation: 0.0
Converged at iteration 4
[INFO][abstract_intensifier.py:590] Added config 3487c8 and rejected config 15f738 as incumbent because it is not better than the incumbents on 3 instances:
Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
violation: 1.0
violation: 0.09825391815362496
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.09827907763642871
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.09828916462103279
violation: 0.0
Converged at iteration 4
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.14180294247293004
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.14175680056288076
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.14172634038001494
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.09495930768735687
violation: 0.012197761707598384
violation: 0.0019811893856268234
violation: 0.0003364348057990567
violation: 5.8909048507025234e-05
Converged at iteration 7
violation: 1.0
violation: 0.09488450578942485
violation: 0.012188078798455761
violation: 0.0019796250816777176
violation: 0.0003361706486857005
violation: 5.8863032796194656e-05
Converged at iteration 7
violation: 1.0
violation: 0.0949478683370498
violation: 0.012196335812149992
violation: 0.00198096009537326
violation: 0.0003363962763698477
violation: 5.890236714175179e-05
Converged at iteration 7
[INFO][abstract_intensifier.py:590] Added config 2d5055 and rejected config 3487c8 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 21d815 and rejected config 2d5055 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.001146730831373318
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.0011467308313733173
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.001146730831373318
violation: 0.0
Converged at iteration 4
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.2773189577098042
violation: 0.12067161105413449
violation: 0.0013212039993906995
violation: 0.0
Converged at iteration 6
violation: 1.0
violation: 0.27731895770980436
violation: 0.12067161105413458
violation: 0.0013212039993907001
violation: 0.0
Converged at iteration 6
violation: 1.0
violation: 0.2773189577098042
violation: 0.1206716110541345
violation: 0.0013212039993906988
violation: 0.0
Converged at iteration 6
Epoch 10 reached after 0.001 seconds, error: 17.856695
Epoch 20 reached after 0.002 seconds, error: 17.752189
Epoch 30 reached after 0.003 seconds, error: 17.752189
Epoch 10 reached after 0.001 seconds, error: 18.151578
Epoch 20 reached after 0.019 seconds, error: 17.955911
Epoch 30 reached after 0.020 seconds, error: 17.885170
Epoch 40 reached after 0.021 seconds, error: 17.752187
Epoch 50 reached after 0.022 seconds, error: 17.752190
Epoch 10 reached after 0.001 seconds, error: 17.763833
Epoch 20 reached after 0.002 seconds, error: 17.752194
Epoch 30 reached after 0.003 seconds, error: 17.752189
[INFO][abstract_intensifier.py:590] Added config 82b073 and rejected config 21d815 as incumbent because it is not better than the incumbents on 3 instances:
Epoch 10 reached after 0.001 seconds, error: 11.543331
Epoch 10 reached after 0.001 seconds, error: 11.543331
Epoch 10 reached after 0.001 seconds, error: 11.543331
violation: 1.0
violation: 0.458122577506821
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.4581225775068208
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.45812257750682084
violation: 0.0
Converged at iteration 4
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha_W': 0.5868929430015201,
  'beta_loss': 'kullback-leibler',
  'init': 'random',
  'l1_ratio': 0.11143798456449737,
  'n_components': 14,
  'solver': 'mu',
  'verbose': 1,
})
Epoch 10 reached after 0.001 seconds, error: 18.127675
Epoch 20 reached after 0.002 seconds, error: 17.872121
Epoch 30 reached after 0.003 seconds, error: 17.752173
Epoch 40 reached after 0.004 seconds, error: 17.752190
Incumbent score ...
0.5349923708199249
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 3bf718 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b2f81c and rejected config 3bf718 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 7e82fc and rejected config b2f81c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config c51ead and rejected config 7e82fc as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config bac496 and rejected config c51ead as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 278519 and rejected config bac496 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 2,
  'n_iter': 5,
  'n_oversamples': 7,
  'power_iteration_normalizer': 'auto',
})
Incumbent score ...
0.4143026868890777
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cee25a as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'batch_size': 98,
  'n_components': 12,
})
Incumbent score ...
0.5591752894307541
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2abf0c as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config ec1bee and rejected config 2abf0c as incumbent because it is not better than the incumbents on 2 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[INFO][abstract_intensifier.py:590] Added config 5ab502 and rejected config ec1bee as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 131, in svd
    raise LinAlgError("SVD did not converge")
numpy.linalg.LinAlgError: SVD did not converge


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 131, in svd
    raise LinAlgError("SVD did not converge")
numpy.linalg.LinAlgError: SVD did not converge


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 131, in svd
    raise LinAlgError("SVD did not converge")
numpy.linalg.LinAlgError: SVD did not converge


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'algorithm': 'deflation',
  'fun': 'logcosh',
  'n_components': 15,
  'whiten_solver': 'svd',
})
Incumbent score ...
0.37341101872726734
Starting runs for the following method: MiniBatch_NMF
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config e0ce77 as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:590] Added config 22397a and rejected config e0ce77 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 9eac0f and rejected config 22397a as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:590] Added config ddab00 and rejected config 9eac0f as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha_W': 0.28388551583176547,
  'batch_size': 1341,
  'beta_loss': 'frobenius',
  'init': 'nndsvdar',
  'l1_ratio': 0.28618486145457844,
  'n_components': 11,
})
Incumbent score ...
0.14636277308700008
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 69482e as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config ef9344 and rejected config 69482e as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 485440 and rejected config ef9344 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d5bfb3 and rejected config 485440 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config e0f1a6 and rejected config d5bfb3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.2564969635758909,
  'method': 'cd',
  'n_components': 11,
  'ridge_alpha': 0.06668294058011304,
})
Incumbent score ...
0.4518511306135573
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config bbef6b as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 04a477 and rejected config bbef6b as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5a5a3c and rejected config 04a477 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 296b79 and rejected config 5a5a3c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 3d4329 and rejected config 296b79 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.15216835220430053,
  'batch_size': 2,
  'method': 'cd',
  'n_components': 15,
  'ridge_alpha': 0.0757912184249834,
})
Incumbent score ...
0.4141099462979795
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 845e22 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config bad155 and rejected config 845e22 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'iterated_power': 5,
  'n_components': 6,
  'rotation': 'quartimax',
  'svd_method': 'randomized',
})
Incumbent score ...
0.6438474670836594
Starting runs for the following method: LDA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 299821 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 19f7e9 and rejected config 299821 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 951db8 and rejected config 19f7e9 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 359017 and rejected config 951db8 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'learning_decay': 0.8224124973189518,
  'learning_method': 'batch',
  'learning_offset': 14.226478996508913,
  'max_iter': 12,
  'n_components': 2,
})
Incumbent score ...
0.06796098553747842
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a6f4d5 and rejected config d953c7 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config bd3661 and rejected config a6f4d5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1b78d5 and rejected config bd3661 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.9571752660778757,
  'early_exaggeration': 5.500790566646723,
  'init': 'random',
  'learning_rate': 648.9925479236014,
  'method': 'barnes_hut',
  'n_components': 3,
  'n_iter': 275,
  'n_iter_without_progress': 216,
  'perplexity': 5.000502533993571,
})
Incumbent score ...
0.17729979753494263
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config acb3a5 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 5ac48c and rejected config acb3a5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config ac822c and rejected config 5ac48c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 58ca1d and rejected config ac822c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1120, in train
    X, X_r = Iso_map(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 189, in Iso_map
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_isomap.py", line 373, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_isomap.py", line 305, in _fit_transform
    self.embedding_ = self.kernel_pca_.fit_transform(G)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 456, in fit_transform
    self.fit(X, **params)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 424, in fit
    self._fit_transform(K)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 335, in _fit_transform
    self.eigenvalues_, self.eigenvectors_ = eigsh(
                                            ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1697, in eigsh
    params.iterate()
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 571, in iterate
    self._raise_no_convergence()
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 377, in _raise_no_convergence
    raise ArpackNoConvergence(msg % (num_iter, k_ok, self.k), ev, vec)
scipy.sparse.linalg._eigen.arpack.arpack.ArpackNoConvergence: ARPACK error -1: No convergence (501 iterations, 9/11 eigenvectors converged)


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1120, in train
    X, X_r = Iso_map(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 189, in Iso_map
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_isomap.py", line 373, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_isomap.py", line 305, in _fit_transform
    self.embedding_ = self.kernel_pca_.fit_transform(G)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 456, in fit_transform
    self.fit(X, **params)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 424, in fit
    self._fit_transform(K)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 335, in _fit_transform
    self.eigenvalues_, self.eigenvectors_ = eigsh(
                                            ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1697, in eigsh
    params.iterate()
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 571, in iterate
    self._raise_no_convergence()
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 377, in _raise_no_convergence
    raise ArpackNoConvergence(msg % (num_iter, k_ok, self.k), ev, vec)
scipy.sparse.linalg._eigen.arpack.arpack.ArpackNoConvergence: ARPACK error -1: No convergence (501 iterations, 9/11 eigenvectors converged)


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1120, in train
    X, X_r = Iso_map(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 189, in Iso_map
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_isomap.py", line 373, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_isomap.py", line 305, in _fit_transform
    self.embedding_ = self.kernel_pca_.fit_transform(G)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 456, in fit_transform
    self.fit(X, **params)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 424, in fit
    self._fit_transform(K)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 335, in _fit_transform
    self.eigenvalues_, self.eigenvectors_ = eigsh(
                                            ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1697, in eigsh
    params.iterate()
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 571, in iterate
    self._raise_no_convergence()
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 377, in _raise_no_convergence
    raise ArpackNoConvergence(msg % (num_iter, k_ok, self.k), ev, vec)
scipy.sparse.linalg._eigen.arpack.arpack.ArpackNoConvergence: ARPACK error -1: No convergence (501 iterations, 9/11 eigenvectors converged)


[INFO][abstract_intensifier.py:590] Added config 50540a and rejected config 58ca1d as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1120, in train
    X, X_r = Iso_map(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 189, in Iso_map
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_isomap.py", line 373, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_isomap.py", line 305, in _fit_transform
    self.embedding_ = self.kernel_pca_.fit_transform(G)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 456, in fit_transform
    self.fit(X, **params)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 424, in fit
    self._fit_transform(K)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 335, in _fit_transform
    self.eigenvalues_, self.eigenvectors_ = eigsh(
                                            ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1697, in eigsh
    params.iterate()
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 571, in iterate
    self._raise_no_convergence()
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 377, in _raise_no_convergence
    raise ArpackNoConvergence(msg % (num_iter, k_ok, self.k), ev, vec)
scipy.sparse.linalg._eigen.arpack.arpack.ArpackNoConvergence: ARPACK error -1: No convergence (501 iterations, 8/11 eigenvectors converged)


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1120, in train
    X, X_r = Iso_map(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 189, in Iso_map
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_isomap.py", line 373, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_isomap.py", line 305, in _fit_transform
    self.embedding_ = self.kernel_pca_.fit_transform(G)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 456, in fit_transform
    self.fit(X, **params)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 424, in fit
    self._fit_transform(K)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 335, in _fit_transform
    self.eigenvalues_, self.eigenvectors_ = eigsh(
                                            ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1697, in eigsh
    params.iterate()
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 571, in iterate
    self._raise_no_convergence()
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 377, in _raise_no_convergence
    raise ArpackNoConvergence(msg % (num_iter, k_ok, self.k), ev, vec)
scipy.sparse.linalg._eigen.arpack.arpack.ArpackNoConvergence: ARPACK error -1: No convergence (501 iterations, 8/11 eigenvectors converged)


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1120, in train
    X, X_r = Iso_map(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 189, in Iso_map
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_isomap.py", line 373, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_isomap.py", line 305, in _fit_transform
    self.embedding_ = self.kernel_pca_.fit_transform(G)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 456, in fit_transform
    self.fit(X, **params)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 424, in fit
    self._fit_transform(K)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_kernel_pca.py", line 335, in _fit_transform
    self.eigenvalues_, self.eigenvectors_ = eigsh(
                                            ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1697, in eigsh
    params.iterate()
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 571, in iterate
    self._raise_no_convergence()
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 377, in _raise_no_convergence
    raise ArpackNoConvergence(msg % (num_iter, k_ok, self.k), ev, vec)
scipy.sparse.linalg._eigen.arpack.arpack.ArpackNoConvergence: ARPACK error -1: No convergence (501 iterations, 8/11 eigenvectors converged)


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'n_components': 2,
  'n_neighbors': 7,
  'neighbors_algorithm': 'auto',
  'path_method': 'D',
})
Incumbent score ...
0.5343733471872516
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 9edc3f as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 1d556c and rejected config 9edc3f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 29536b and rejected config 1d556c as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 05fb9e and rejected config 29536b as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'method': 'standard',
  'n_components': 2,
  'n_neighbors': 25,
  'neighbors_algorithm': 'kd_tree',
})
Incumbent score ...
0.5575926569787251
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 439630 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config e46e22 and rejected config 439630 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 271fe4 and rejected config e46e22 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 87e7bf and rejected config 271fe4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config bac5bd and rejected config 87e7bf as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 772003 and rejected config bac5bd as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 8f6286 and rejected config 772003 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 5,
})
Incumbent score ...
0.5362909100021233
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config face95 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 514153 and rejected config face95 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config c04d5b and rejected config 514153 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'amg',
  'n_components': 2,
})
Incumbent score ...
0.44669708402910313
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 156b0c and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'dice',
  'min_dist': 0.6645437930300775,
  'n_components': 2,
  'n_neighbors': 20,
})
Incumbent score ...
0.22678017616271973
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
  optimized_method     score                                          incumbent
0              LDA  0.067961  {'learning_decay': 0.8224124973189518, 'learni...
LDA
{'learning_decay': 0.8224124973189518, 'learning_method': 'batch', 'learning_offset': 14.226478996508913, 'max_iter': 12, 'n_components': 2}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
LDA
Initiating Consensus Clustering...
LDA
Initiating Consensus Clustering...
LDA
Mean score from Consensus Clustering is...
0.06899919089472928
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config f6d977 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config c19229 and rejected config f6d977 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 82b0e0 and rejected config c19229 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b87e65 and rejected config 82b0e0 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 2,
  'n_oversamples': 8,
  'power_iteration_normalizer': 'auto',
  'svd_solver': 'randomized',
})
Incumbent score ...
0.52069645678756
Starting runs for the following method: NMF_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:515] Added config 73bc4a as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.0
Converged at iteration 3
violation: 1.0
violation: 0.0
Converged at iteration 3
[INFO][abstract_intensifier.py:590] Added config 15f738 and rejected config 73bc4a as incumbent because it is not better than the incumbents on 2 instances:
violation: 1.0
violation: 0.0
Converged at iteration 3
violation: 1.0
violation: 0.05199853436330186
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.05199162773221899
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.0519926333519815
violation: 0.0
Converged at iteration 4
[INFO][abstract_intensifier.py:590] Added config 3487c8 and rejected config 15f738 as incumbent because it is not better than the incumbents on 3 instances:
Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
violation: 1.0
violation: 0.09825898425207859
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.09828169881998697
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.09824052227452003
violation: 0.0
Converged at iteration 4
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
Epoch 10 reached after 0.001 seconds, error: 23.210584
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.14172627617742223
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.14170143850777464
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.14177091638948666
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.09496969581492211
violation: 0.012199165695248199
violation: 0.0019814182191364538
violation: 0.0003364737281795296
violation: 5.891587222504961e-05
Converged at iteration 7
violation: 1.0
violation: 0.09495967921259688
violation: 0.012197948070704496
violation: 0.0019812202958826414
violation: 0.000336440071573298
violation: 5.890997130894771e-05
Converged at iteration 7
violation: 1.0
violation: 0.09489675125963669
violation: 0.012189807616217773
violation: 0.001979905450361933
violation: 0.00033621814787775415
violation: 5.8871331087694586e-05
Converged at iteration 7
[INFO][abstract_intensifier.py:590] Added config 2d5055 and rejected config 3487c8 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 21d815 and rejected config 2d5055 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.001146730831373318
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.0011467308313733182
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.001146730831373318
violation: 0.0
Converged at iteration 4
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


violation: 1.0
violation: 0.27731895770980436
violation: 0.1206716110541346
violation: 0.0013212039993906993
violation: 0.0
Converged at iteration 6
violation: 1.0
violation: 0.27731895770980425
violation: 0.1206716110541345
violation: 0.0013212039993906993
violation: 0.0
Converged at iteration 6
violation: 1.0
violation: 0.27731895770980447
violation: 0.12067161105413463
violation: 0.0013212039993906997
violation: 0.0
Converged at iteration 6
Epoch 10 reached after 0.001 seconds, error: 17.774781
Epoch 20 reached after 0.002 seconds, error: 17.752198
Epoch 30 reached after 0.006 seconds, error: 17.752189
Epoch 10 reached after 0.005 seconds, error: 18.104924
Epoch 20 reached after 0.006 seconds, error: 17.906707
Epoch 30 reached after 0.007 seconds, error: 17.752146
Epoch 40 reached after 0.008 seconds, error: 17.752189
Epoch 10 reached after 0.003 seconds, error: 17.793092
Epoch 20 reached after 0.004 seconds, error: 17.752207
Epoch 30 reached after 0.005 seconds, error: 17.752189
[INFO][abstract_intensifier.py:590] Added config 82b073 and rejected config 21d815 as incumbent because it is not better than the incumbents on 3 instances:
Epoch 10 reached after 0.001 seconds, error: 11.543331
Epoch 10 reached after 0.001 seconds, error: 11.543331
Epoch 10 reached after 0.001 seconds, error: 11.543331
violation: 1.0
violation: 0.45812257750682106
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.45812257750682084
violation: 0.0
Converged at iteration 4
violation: 1.0
violation: 0.45812257750682106
violation: 0.0
Converged at iteration 4
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 700, in train
    X, X_r = NMF_sklearn(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 59, in NMF_sklearn
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1566, in fit_transform
    W, H, n_iter = self._fit_transform(X, W=W, H=H)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 1618, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha_W': 0.5868929430015201,
  'beta_loss': 'kullback-leibler',
  'init': 'random',
  'l1_ratio': 0.11143798456449737,
  'n_components': 14,
  'solver': 'mu',
  'verbose': 1,
})
Epoch 10 reached after 0.012 seconds, error: 18.307545
Epoch 20 reached after 0.013 seconds, error: 17.752149
Epoch 30 reached after 0.014 seconds, error: 17.752190
Incumbent score ...
0.5349923629139532
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 3bf718 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b2f81c and rejected config 3bf718 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e6d3e4 and rejected config b2f81c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_iter': 3,
  'n_oversamples': 10,
  'power_iteration_normalizer': 'LU',
})
Incumbent score ...
0.4143026868890748
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cee25a as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'batch_size': 98,
  'n_components': 12,
})
Incumbent score ...
0.5591752894307541
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2abf0c as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config ec1bee and rejected config 2abf0c as incumbent because it is not better than the incumbents on 2 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[INFO][abstract_intensifier.py:590] Added config 5ab502 and rejected config ec1bee as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 654, in _fit_transform
    W, n_iter = _ica_par(X1, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 113, in _ica_par
    W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 56, in _sym_decorrelation
    s, u = linalg.eigh(np.dot(W, W.T))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp.py", line 461, in eigh
    a1 = _asarray_validated(a, check_finite=check_finite)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/_lib/_util.py", line 252, in _asarray_validated
    a = toarray(a)
        ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/numpy/lib/function_base.py", line 628, in asarray_chkfinite
    raise ValueError(
ValueError: array must not contain infs or NaNs


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 131, in svd
    raise LinAlgError("SVD did not converge")
numpy.linalg.LinAlgError: SVD did not converge


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 131, in svd
    raise LinAlgError("SVD did not converge")
numpy.linalg.LinAlgError: SVD did not converge


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 131, in svd
    raise LinAlgError("SVD did not converge")
numpy.linalg.LinAlgError: SVD did not converge


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'algorithm': 'deflation',
  'fun': 'logcosh',
  'n_components': 15,
  'whiten_solver': 'svd',
})
Incumbent score ...
0.37341101872726734
Starting runs for the following method: MiniBatch_NMF
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config e0ce77 as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:590] Added config 22397a and rejected config e0ce77 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 9eac0f and rejected config 22397a as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][abstract_intensifier.py:590] Added config ddab00 and rejected config 9eac0f as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 738, in train
    X, X_r = MiniBatch_NMF(X_scaled, **config_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 142, in MiniBatch_NMF
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2143, in fit_transform
    W, H, n_iter, n_steps = self._fit_transform(X, W=W, H=H)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_nmf.py", line 2195, in _fit_transform
    raise ValueError(
ValueError: When beta_loss <= 0 and X contains zeros, the solver may diverge. Please add small values to X, or use a positive beta_loss.


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha_W': 0.28388551583176547,
  'batch_size': 1341,
  'beta_loss': 'frobenius',
  'init': 'nndsvdar',
  'l1_ratio': 0.28618486145457844,
  'n_components': 11,
})
Incumbent score ...
0.146362772805264
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 69482e as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a8c3aa and rejected config 69482e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config fb32e0 and rejected config a8c3aa as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b50837 and rejected config fb32e0 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 87697d and rejected config b50837 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.17153537732415391,
  'method': 'cd',
  'n_components': 14,
  'ridge_alpha': 0.09760528310690084,
})
Incumbent score ...
0.5356475163945899
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config bbef6b as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config dff6d1 and rejected config bbef6b as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 5a5a3c and rejected config dff6d1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 92af4b and rejected config 5a5a3c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.534446463814666,
  'batch_size': 3,
  'method': 'cd',
  'n_components': 11,
  'ridge_alpha': 0.07051150235912147,
})
Incumbent score ...
0.6080000241512418
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 845e22 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config bad155 and rejected config 845e22 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'iterated_power': 5,
  'n_components': 6,
  'rotation': 'quartimax',
  'svd_method': 'randomized',
})
Incumbent score ...
0.6438474670836594
Starting runs for the following method: LDA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 299821 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 19f7e9 and rejected config 299821 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 1d6bb0 and rejected config 19f7e9 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 1b1c3a and rejected config 1d6bb0 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'learning_decay': 0.872087011032378,
  'learning_method': 'batch',
  'learning_offset': 5.422697086455924,
  'max_iter': 14,
  'n_components': 2,
})
Incumbent score ...
0.06899919089810025
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a6f4d5 and rejected config d953c7 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 41fa38 and rejected config a6f4d5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.7997621418908238,
  'early_exaggeration': 14.138102843426168,
  'init': 'pca',
  'learning_rate': 767.6541746348772,
  'method': 'barnes_hut',
  'n_components': 3,
  'n_iter': 304,
  'n_iter_without_progress': 181,
  'perplexity': 5.4076589201007454,
})
Incumbent score ...
0.08409875631332397
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config acb3a5 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 571073 and rejected config acb3a5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 944c5b and rejected config 571073 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 50540a and rejected config 944c5b as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'n_components': 2,
  'n_neighbors': 7,
  'neighbors_algorithm': 'auto',
  'path_method': 'D',
})
Incumbent score ...
0.5343733471872516
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 9edc3f as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 1d556c and rejected config 9edc3f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 500a3a and rejected config 1d556c as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[INFO][abstract_intensifier.py:590] Added config 4b04ec and rejected config 500a3a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'method': 'ltsa',
  'n_components': 3,
  'n_neighbors': 26,
  'neighbors_algorithm': 'kd_tree',
})
Incumbent score ...
0.5135788774859101
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 439630 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config e46e22 and rejected config 439630 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 271fe4 and rejected config e46e22 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 87e7bf and rejected config 271fe4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config bac5bd and rejected config 87e7bf as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 772003 and rejected config bac5bd as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 3,
})
Incumbent score ...
0.5362464304629067
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config face95 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 514153 and rejected config face95 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d88084 and rejected config 514153 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'lobpcg',
  'n_components': 2,
})
Incumbent score ...
0.44669036251332106
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config f6e378 and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 35e376 and rejected config f6e378 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'correlation',
  'min_dist': 0.954026132896019,
  'n_components': 2,
  'n_neighbors': 16,
})
Incumbent score ...
0.2203538417816162
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
  optimized_method     score                                          incumbent
0              LDA  0.068999  {'learning_decay': 0.872087011032378, 'learnin...
LDA
{'learning_decay': 0.872087011032378, 'learning_method': 'batch', 'learning_offset': 5.422697086455924, 'max_iter': 14, 'n_components': 2}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
LDA
Initiating Consensus Clustering...
LDA
Initiating Consensus Clustering...
LDA
Mean score from Consensus Clustering is...
0.06830705399720764
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 055ddd as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config c19229 and rejected config 055ddd as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1ac906 and rejected config c19229 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1ea441 and rejected config 1ac906 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_oversamples': 8,
  'power_iteration_normalizer': 'QR',
  'svd_solver': 'randomized',
})
Incumbent score ...
0.4569568711978236
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 33cdb6 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b2f81c and rejected config 33cdb6 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 3a4c79 and rejected config b2f81c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config e62079 and rejected config 3a4c79 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 2,
  'n_iter': 6,
  'n_oversamples': 4,
  'power_iteration_normalizer': 'OR',
})
Incumbent score ...
0.4572503986973899
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 745058 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 6a26cd and rejected config 745058 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 3332e5 and rejected config 6a26cd as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 07916a and rejected config 3332e5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5745cc and rejected config 07916a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 44c605 and rejected config 5745cc as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config e71ead and rejected config 44c605 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 39d2c0 and rejected config e71ead as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'batch_size': 95,
  'n_components': 2,
})
Incumbent score ...
0.45695808053826614
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2abf0c as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 8924b7 and rejected config 2abf0c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 65a0ac and rejected config 8924b7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'algorithm': 'parallel',
  'fun': 'exp',
  'n_components': 2,
  'whiten_solver': 'svd',
})
Incumbent score ...
0.6063772805385024
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 69482e as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 32efb3 and rejected config 69482e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config ee235d and rejected config 32efb3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 0c70b1 and rejected config ee235d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config e56290 and rejected config 0c70b1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 977440 and rejected config e56290 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 883dba and rejected config 977440 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.913973074720688,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.05587706263134497,
})
Incumbent score ...
0.45745921937920986
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 415833 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 21657b and rejected config 415833 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 0c8b3c and rejected config 21657b as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 859626 and rejected config 0c8b3c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config f2b7e3 and rejected config 859626 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d10e36 and rejected config f2b7e3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d0a896 and rejected config d10e36 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 5b560f and rejected config d0a896 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config caf02d and rejected config 5b560f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5edd17 and rejected config caf02d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.33146788854250453,
  'batch_size': 4,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.0828566596919907,
})
Incumbent score ...
0.4591743751663476
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 479a03 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 3414a9 and rejected config 479a03 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config a70b30 and rejected config 3414a9 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 444e47 and rejected config a70b30 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'iterated_power': 4,
  'n_components': 14,
  'rotation': 'quartimax',
  'svd_method': 'lapack',
})
Incumbent score ...
0.4495926408251292
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a6f4d5 and rejected config d953c7 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config cfd021 and rejected config a6f4d5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config dda54f and rejected config cfd021 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.8255745901414772,
  'early_exaggeration': 36.67498625931648,
  'init': 'random',
  'learning_rate': 920.2877876072268,
  'method': 'exact',
  'n_components': 3,
  'n_iter': 362,
  'n_iter_without_progress': 441,
  'perplexity': 12.312182060436868,
})
Incumbent score ...
0.21182280778884888
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c87436 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config c87436 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config bfb0ab and rejected config 1e6abb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 6845e4 and rejected config bfb0ab as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 33ba0e and rejected config 6845e4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 53eb71 and rejected config 33ba0e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'dense',
  'n_components': 3,
  'n_neighbors': 6,
  'neighbors_algorithm': 'brute',
  'path_method': 'D',
})
Incumbent score ...
0.4434392856875572
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 29afb0 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 29a829 and rejected config 29afb0 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 451c63 and rejected config 29a829 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'method': 'modified',
  'n_components': 2,
  'n_neighbors': 21,
  'neighbors_algorithm': 'kd_tree',
})
Incumbent score ...
0.45950171860375055
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 248200 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 48c752 and rejected config 248200 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 271fe4 and rejected config 48c752 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 87e7bf and rejected config 271fe4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 772003 and rejected config 87e7bf as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 792ad1 and rejected config 772003 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 2,
})
Incumbent score ...
0.47548240521730945
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config face95 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 99da96 and rejected config face95 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'rbf',
  'eigen_solver': 'lobpcg',
  'n_components': 2,
})
Incumbent score ...
0.3509733064347925
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 3e0ae7 and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config aa8847 and rejected config 3e0ae7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b7eb6d and rejected config aa8847 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
ZeroDivisionError: division by zero


[INFO][smbo.py:319] Finished 50 trials.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2439, in fit
    dmat = pairwise_distances(X[index], metric=_m, **self._metric_kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1261, in train
    X, X_r = U_MAP(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 221, in U_MAP
    X_hat = reducer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2772, in fit_transform
    self.fit(X, y)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/umap_.py", line 2460, in fit
    dmat = dist.pairwise_special_metric(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 1297, in pairwise_special_metric
    return pairwise_distances(X, Y, metric=_partial_metric)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
           ^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1606, in _pairwise_callable
    out[i, j] = metric(X[i], Y[j], **kwds)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/umap/distances.py", line 497, in haversine
    raise ValueError("haversine is only defined for 2 dimensional data")
ValueError: haversine is only defined for 2 dimensional data


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'cosine',
  'min_dist': 0.003221174104809828,
  'n_components': 2,
  'n_neighbors': 26,
})
Incumbent score ...
0.06857514381408691
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
  optimized_method     score                                          incumbent
0            U_MAP  0.068575  {'metric': 'cosine', 'min_dist': 0.00322117410...
U_MAP
{'metric': 'cosine', 'min_dist': 0.003221174104809828, 'n_components': 2, 'n_neighbors': 26}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
U_MAP
Initiating Consensus Clustering...
U_MAP
Initiating Consensus Clustering...
U_MAP
Mean score from Consensus Clustering is...
0.055823683738708496
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 6bdad4 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config c19229 and rejected config 6bdad4 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'svd_solver': 'full',
})
Incumbent score ...
0.5269729782885317
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 36489d as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b2f81c and rejected config 36489d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 2,
  'n_iter': 5,
  'n_oversamples': 11,
  'power_iteration_normalizer': 'LU',
})
Incumbent score ...
0.5269729782885317
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 8e41da as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config f3ae6c and rejected config 8e41da as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 9ec9b7 and rejected config f3ae6c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 484733 and rejected config 9ec9b7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'batch_size': 31,
  'n_components': 2,
})
Incumbent score ...
0.5269973838585342
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cbf288 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 77510f and rejected config cbf288 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'algorithm': 'deflation',
  'fun': 'exp',
  'n_components': 2,
  'whiten_solver': 'svd',
})
Incumbent score ...
0.4681393170653104
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2207a2 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 726ccd and rejected config 2207a2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b58709 and rejected config 726ccd as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config fd3aa1 and rejected config b58709 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config f38242 and rejected config fd3aa1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d6f5a6 and rejected config f38242 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config ef54de and rejected config d6f5a6 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 126c8e and rejected config ef54de as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.10770726396449731,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.015705497003847078,
})
Incumbent score ...
0.5231646491809366
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 53e5f5 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 8560d7 and rejected config 53e5f5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 291f6e and rejected config 8560d7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.35452047454488766,
  'batch_size': 3,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.09788601446464222,
})
Incumbent score ...
0.5303098817677908
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config b7bd7d as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 791352 and rejected config b7bd7d as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 74018d and rejected config 791352 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 78081a and rejected config 74018d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'iterated_power': 4,
  'n_components': 2,
  'rotation': 'varimax',
  'svd_method': 'randomized',
})
Incumbent score ...
0.4662084388572527
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 6721d5 and rejected config d953c7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config dda54f and rejected config 6721d5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e38d5f and rejected config dda54f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.9563981057337311,
  'early_exaggeration': 35.53783585790145,
  'init': 'pca',
  'learning_rate': 953.1631238338691,
  'method': 'barnes_hut',
  'n_components': 3,
  'n_iter': 365,
  'n_iter_without_progress': 432,
  'perplexity': 13.025927488394242,
})
Incumbent score ...
0.27925628423690796
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 00efea as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config 00efea as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e02168 and rejected config 1e6abb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'n_components': 2,
  'n_neighbors': 5,
  'neighbors_algorithm': 'ball_tree',
  'path_method': 'FW',
})
Incumbent score ...
0.4564047052469504
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d54060 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config ede098 and rejected config d54060 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config a9c145 and rejected config ede098 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 158a8f and rejected config a9c145 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'arpack',
  'method': 'standard',
  'n_components': 2,
  'n_neighbors': 5,
  'neighbors_algorithm': 'auto',
})
Incumbent score ...
0.4633709000797662
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 74a6b2 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 87e7bf and rejected config 74a6b2 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 7a96f4 and rejected config 87e7bf as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 8f6286 and rejected config 7a96f4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 792ad1 and rejected config 8f6286 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 2,
})
Incumbent score ...
0.528428504715448
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c04d5b as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config d88084 and rejected config c04d5b as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'lobpcg',
  'n_components': 2,
})
Incumbent score ...
0.335226496788291
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config ce0332 and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 0d0af8 and rejected config ce0332 as incumbent because it is not better than the incumbents on 3 instances:
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'canberra',
  'min_dist': 0.0859109481535842,
  'n_components': 3,
  'n_neighbors': 13,
})
Incumbent score ...
0.185596764087677
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
  optimized_method     score                                          incumbent
0            U_MAP  0.185597  {'metric': 'canberra', 'min_dist': 0.085910948...
U_MAP
{'metric': 'canberra', 'min_dist': 0.0859109481535842, 'n_components': 3, 'n_neighbors': 13}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
U_MAP
Initiating Consensus Clustering...
U_MAP
Initiating Consensus Clustering...
U_MAP
Mean score from Consensus Clustering is...
0.18858222166697183
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 4 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c19229 as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'svd_solver': 'full',
})
Incumbent score ...
0.4014100758803064
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 430fad as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b2f81c and rejected config 430fad as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_iter': 5,
  'n_oversamples': 11,
  'power_iteration_normalizer': 'LU',
})
Incumbent score ...
0.4014100758803064
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d3d156 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a648c2 and rejected config d3d156 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 812c59 and rejected config a648c2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b77c39 and rejected config 812c59 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 1f8aab and rejected config b77c39 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'batch_size': 43,
  'n_components': 2,
})
Incumbent score ...
0.3998713598444832
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cbf288 as new incumbent because there are no incumbents yet.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'algorithm': 'parallel',
  'fun': 'exp',
  'n_components': 2,
  'whiten_solver': 'eigh',
})
Incumbent score ...
0.41083467778517946
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2207a2 as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 91b3bd and rejected config 2207a2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 04b520 and rejected config 91b3bd as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1e5d79 and rejected config 04b520 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 98710c and rejected config 1e5d79 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.1499632649163013,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.061933210946584945,
})
Incumbent score ...
0.406239506794289
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 53e5f5 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 5df8a2 and rejected config 53e5f5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.68729985767853,
  'batch_size': 3,
  'method': 'cd',
  'n_components': 2,
  'ridge_alpha': 0.09268334815623724,
})
Incumbent score ...
0.40978504263216664
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 409ec3 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 791352 and rejected config 409ec3 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config a32b8c and rejected config 791352 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 20ed68 and rejected config a32b8c as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'iterated_power': 3,
  'n_components': 4,
  'rotation': 'varimax',
  'svd_method': 'randomized',
})
Incumbent score ...
0.4041077206447209
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 026fe4 and rejected config d953c7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 67eb3a and rejected config 026fe4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5d942f and rejected config 67eb3a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 198607 and rejected config 5d942f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.5785503510476759,
  'early_exaggeration': 30.477898476333472,
  'init': 'pca',
  'learning_rate': 527.2828990709622,
  'method': 'exact',
  'n_components': 2,
  'n_iter': 758,
  'n_iter_without_progress': 135,
  'perplexity': 8.696221997171513,
})
Incumbent score ...
0.25575220584869385
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 043649 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config 043649 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 45eacd and rejected config 1e6abb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 2257fd and rejected config 45eacd as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 265b11 and rejected config 2257fd as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'dense',
  'n_components': 2,
  'n_neighbors': 5,
  'neighbors_algorithm': 'ball_tree',
  'path_method': 'FW',
})
Incumbent score ...
0.3095606229847335
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 42d1dc as new incumbent because there are no incumbents yet.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config 7f8889 and rejected config 42d1dc as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config cec145 and rejected config 7f8889 as incumbent because it is not better than the incumbents on 3 instances:
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][smbo.py:319] Finished 50 trials.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config 3a7349 and rejected config cec145 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 862a56 and rejected config 3a7349 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'dense',
  'method': 'ltsa',
  'n_components': 2,
  'n_neighbors': 6,
  'neighbors_algorithm': 'auto',
})
Incumbent score ...
0.020000000003395857
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 670869 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 8f6286 and rejected config 670869 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 772003 and rejected config 8f6286 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 3,
})
Incumbent score ...
0.4448055196510885
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c04d5b as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config d88084 and rejected config c04d5b as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'lobpcg',
  'n_components': 2,
})
Incumbent score ...
0.15077100993515302
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 15ebaa and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1dbd22 and rejected config 15ebaa as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 5126f5 and rejected config 1dbd22 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 2ed56b and rejected config 5126f5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 740dd0 and rejected config 2ed56b as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'correlation',
  'min_dist': 0.0021950037606456797,
  'n_components': 2,
  'n_neighbors': 19,
})
Incumbent score ...
0.15708738565444946
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
         optimized_method  ...                                          incumbent
0  Local_Linear_Embedding  ...  {'eigen_solver': 'dense', 'method': 'ltsa', 'n...

[1 rows x 3 columns]
Local_Linear_Embedding
{'eigen_solver': 'dense', 'method': 'ltsa', 'n_components': 2, 'n_neighbors': 6, 'neighbors_algorithm': 'auto'}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
Local_Linear_Embedding
Initiating Consensus Clustering...
Local_Linear_Embedding
Initiating Consensus Clustering...
Local_Linear_Embedding
Mean score from Consensus Clustering is...
0.020000000003395857
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 4 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c19229 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 52eff5 and rejected config c19229 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1195f3 and rejected config 52eff5 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_oversamples': 9,
  'power_iteration_normalizer': 'auto',
  'svd_solver': 'randomized',
})
Incumbent score ...
0.5733432463218506
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 430fad as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 2,
  'n_iter': 6,
  'n_oversamples': 3,
  'power_iteration_normalizer': 'auto',
})
Incumbent score ...
0.5733432463218505
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 9d6cc0 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 286f40 and rejected config 9d6cc0 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 73ceac and rejected config 286f40 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b77c39 and rejected config 73ceac as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 812c59 and rejected config b77c39 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'batch_size': 41,
  'n_components': 2,
})
Incumbent score ...
0.5713712915640936
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cbf288 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 35abd8 and rejected config cbf288 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'algorithm': 'parallel',
  'fun': 'logcosh',
  'n_components': 2,
  'whiten_solver': 'svd',
})
Incumbent score ...
0.6105947932380189
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2207a2 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b97433 and rejected config 2207a2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config be2fa8 and rejected config b97433 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 75a1f2 and rejected config be2fa8 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d7f64e and rejected config 75a1f2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 2cf0bc and rejected config d7f64e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 95b158 and rejected config 2cf0bc as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.19182432787497342,
  'method': 'cd',
  'n_components': 2,
  'ridge_alpha': 0.011249827061900815,
})
Incumbent score ...
0.5729626342000739
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 53e5f5 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config f52dc1 and rejected config 53e5f5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 7ff9bc and rejected config f52dc1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 51cad4 and rejected config 7ff9bc as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 8ef07f and rejected config 51cad4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 136129 and rejected config 8ef07f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b9e464 and rejected config 136129 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 910654 and rejected config b9e464 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.8435211164031885,
  'batch_size': 2,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.022666465335855337,
})
Incumbent score ...
0.5677009832118798
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 409ec3 as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'iterated_power': 3,
  'n_components': 3,
  'rotation': 'varimax',
  'svd_method': 'lapack',
})
Incumbent score ...
0.3343839461445337
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a6f4d5 and rejected config d953c7 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 424b62 and rejected config a6f4d5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 611784 and rejected config 424b62 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.6540036078554597,
  'early_exaggeration': 10.571899228224868,
  'init': 'pca',
  'learning_rate': 809.2457691377606,
  'method': 'exact',
  'n_components': 2,
  'n_iter': 301,
  'n_iter_without_progress': 364,
  'perplexity': 25.409420720513097,
})
Incumbent score ...
0.11742323637008667
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 043649 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config aab2c3 and rejected config 043649 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config aab2c3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1275b5 and rejected config 1e6abb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 45eacd and rejected config 1275b5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 265b11 and rejected config 45eacd as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'dense',
  'n_components': 2,
  'n_neighbors': 5,
  'neighbors_algorithm': 'ball_tree',
  'path_method': 'FW',
})
Incumbent score ...
0.46601732322865497
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2d4953 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 852251 and rejected config 2d4953 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5f16f3 and rejected config 852251 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config f83e33 and rejected config 5f16f3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e0039f and rejected config f83e33 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d6a520 and rejected config e0039f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1ce042 and rejected config d6a520 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config faaec9 and rejected config 1ce042 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'eigen_solver': 'dense',
  'method': 'standard',
  'n_components': 2,
  'n_neighbors': 3,
  'neighbors_algorithm': 'ball_tree',
})
Incumbent score ...
0.3521566656125651
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 670869 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 8f6286 and rejected config 670869 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 7a96f4 and rejected config 8f6286 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 772003 and rejected config 7a96f4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 792ad1 and rejected config 772003 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 2,
})
Incumbent score ...
0.5896465462077758
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c04d5b as new incumbent because there are no incumbents yet.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'amg',
  'n_components': 2,
})
Incumbent score ...
0.4814761924917791
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config 7b9c2b and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config baf181 and rejected config 7b9c2b as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config bbbe3a and rejected config baf181 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'wminkowski',
  'min_dist': 0.4291270943064573,
  'n_components': 2,
  'n_neighbors': 19,
})
Incumbent score ...
0.3659552335739136
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
  optimized_method     score                                          incumbent
0            t_SNE  0.117423  {'angle': 0.6540036078554597, 'early_exaggerat...
t_SNE
{'angle': 0.6540036078554597, 'early_exaggeration': 10.571899228224868, 'init': 'pca', 'learning_rate': 809.2457691377606, 'method': 'exact', 'n_components': 2, 'n_iter': 301, 'n_iter_without_progress': 364, 'perplexity': 25.409420720513097}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
t_SNE
Initiating Consensus Clustering...
t_SNE
Initiating Consensus Clustering...
t_SNE
Mean score from Consensus Clustering is...
0.11742323637008667
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 4 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c19229 as new incumbent because there are no incumbents yet.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'svd_solver': 'full',
})
Incumbent score ...
0.6854851076685753
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 430fad as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config b2f81c and rejected config 430fad as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 294965 and rejected config b2f81c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 1aad80 and rejected config 294965 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'n_iter': 6,
  'n_oversamples': 5,
  'power_iteration_normalizer': 'LU',
})
Incumbent score ...
0.6854851076685756
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 9d6cc0 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 286f40 and rejected config 9d6cc0 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'batch_size': 34,
  'n_components': 2,
})
Incumbent score ...
0.6312903489560815
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cbf288 as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'algorithm': 'parallel',
  'fun': 'exp',
  'n_components': 2,
  'whiten_solver': 'eigh',
})
Incumbent score ...
0.6860226872845351
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2207a2 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config ea96b3 and rejected config 2207a2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config dd2903 and rejected config ea96b3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config bab0eb and rejected config dd2903 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.9493732706631618,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.06906966305187462,
})
Incumbent score ...
0.6541703608538048
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 53e5f5 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 715da3 and rejected config 53e5f5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config f399b2 and rejected config 715da3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e5a6aa and rejected config f399b2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 35ab69 and rejected config e5a6aa as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config a2f771 and rejected config 35ab69 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e4ed20 and rejected config a2f771 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 9850a3 and rejected config e4ed20 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 707770 and rejected config 9850a3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.11308231219927078,
  'batch_size': 2,
  'method': 'cd',
  'n_components': 2,
  'ridge_alpha': 0.03804576000154022,
})
Incumbent score ...
0.6662094592424079
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 409ec3 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a9ed04 and rejected config 409ec3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 647ad2 and rejected config a9ed04 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'iterated_power': 5,
  'n_components': 3,
  'rotation': 'quartimax',
  'svd_method': 'randomized',
})
Incumbent score ...
0.4859785020837608
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a6f4d5 and rejected config d953c7 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 8606ce and rejected config a6f4d5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.8054978890163731,
  'early_exaggeration': 15.125526991952695,
  'init': 'pca',
  'learning_rate': 599.4735804867455,
  'method': 'exact',
  'n_components': 3,
  'n_iter': 323,
  'n_iter_without_progress': 211,
  'perplexity': 7.327278139781555,
})
Incumbent score ...
0.1846376657485962
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 043649 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config aab2c3 and rejected config 043649 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config aab2c3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 01928f and rejected config 1e6abb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 87655d and rejected config 01928f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b2ddba and rejected config 87655d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 95dd7a and rejected config b2ddba as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'n_components': 2,
  'n_neighbors': 5,
  'neighbors_algorithm': 'brute',
  'path_method': 'FW',
})
Incumbent score ...
0.5409871914698247
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2d4953 as new incumbent because there are no incumbents yet.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config b33007 and rejected config 2d4953 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 5c6c0a and rejected config b33007 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[INFO][abstract_intensifier.py:590] Added config b048b4 and rejected config 5c6c0a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config f83e33 and rejected config b048b4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 356ca5 and rejected config f83e33 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'dense',
  'method': 'modified',
  'n_components': 3,
  'n_neighbors': 3,
  'neighbors_algorithm': 'kd_tree',
})
Incumbent score ...
0.0439978281173663
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 670869 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 8f6286 and rejected config 670869 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 7a96f4 and rejected config 8f6286 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 772003 and rejected config 7a96f4 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 3,
})
Incumbent score ...
0.6642608596742526
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c04d5b as new incumbent because there are no incumbents yet.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'amg',
  'n_components': 2,
})
Incumbent score ...
0.5606047411120297
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config 25ec28 and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 2bc1c9 and rejected config 25ec28 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 74b25b and rejected config 2bc1c9 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 9215c7 and rejected config 74b25b as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'correlation',
  'min_dist': 0.13911437776173882,
  'n_components': 2,
  'n_neighbors': 9,
})
Incumbent score ...
0.5822224915027618
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
         optimized_method  ...                                          incumbent
0  Local_Linear_Embedding  ...  {'eigen_solver': 'dense', 'method': 'modified'...

[1 rows x 3 columns]
Local_Linear_Embedding
{'eigen_solver': 'dense', 'method': 'modified', 'n_components': 3, 'n_neighbors': 3, 'neighbors_algorithm': 'kd_tree'}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
Local_Linear_Embedding
Initiating Consensus Clustering...
Local_Linear_Embedding
Initiating Consensus Clustering...
Local_Linear_Embedding
Mean score from Consensus Clustering is...
0.0439978281173663
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 4 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c19229 as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'n_components': 2,
  'svd_solver': 'full',
})
Incumbent score ...
0.6229398220199731
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 430fad as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config e83848 and rejected config 430fad as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e62079 and rejected config e83848 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config d0a999 and rejected config e62079 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config af2886 and rejected config d0a999 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 2,
  'n_iter': 3,
  'n_oversamples': 7,
  'power_iteration_normalizer': 'auto',
})
Incumbent score ...
0.6276639692110333
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 9d6cc0 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 286f40 and rejected config 9d6cc0 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 130a30 and rejected config 286f40 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d576b0 and rejected config 130a30 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'batch_size': 28,
  'n_components': 2,
})
Incumbent score ...
0.655786494240709
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config cbf288 as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'algorithm': 'parallel',
  'fun': 'exp',
  'n_components': 2,
  'whiten_solver': 'eigh',
})
Incumbent score ...
0.6257052077730008
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2207a2 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config ea96b3 and rejected config 2207a2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config df3921 and rejected config ea96b3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 9535b9 and rejected config df3921 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 63d50a and rejected config 9535b9 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 55d363 and rejected config 63d50a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 111023 and rejected config 55d363 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.6721333310620056,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.02843536825089507,
})
Incumbent score ...
0.6184971198922171
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 53e5f5 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 715da3 and rejected config 53e5f5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 56cb89 and rejected config 715da3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 31163e and rejected config 56cb89 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config d8dba2 and rejected config 31163e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 4278e7 and rejected config d8dba2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.7942804368027394,
  'batch_size': 3,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.04555692553568415,
})
Incumbent score ...
0.6206979587168426
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 409ec3 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a9ed04 and rejected config 409ec3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 647ad2 and rejected config a9ed04 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 0e3dfd and rejected config 647ad2 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'iterated_power': 4,
  'n_components': 3,
  'rotation': 'quartimax',
  'svd_method': 'randomized',
})
Incumbent score ...
0.6560330841694926
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a6f4d5 and rejected config d953c7 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 728e00 and rejected config a6f4d5 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.7735532994811044,
  'early_exaggeration': 13.670110146977054,
  'init': 'pca',
  'learning_rate': 596.0679089464247,
  'method': 'exact',
  'n_components': 3,
  'n_iter': 405,
  'n_iter_without_progress': 309,
  'perplexity': 8.030356685630977,
})
Incumbent score ...
0.33334970474243164
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 043649 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config aab2c3 and rejected config 043649 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config aab2c3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config b2ddba and rejected config 1e6abb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'n_components': 2,
  'n_neighbors': 5,
  'neighbors_algorithm': 'kd_tree',
  'path_method': 'FW',
})
Incumbent score ...
0.6665899603722023
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 2d4953 as new incumbent because there are no incumbents yet.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config b33007 and rejected config 2d4953 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 7df0ca and rejected config b33007 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config 356ca5 and rejected config 7df0ca as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'dense',
  'method': 'modified',
  'n_components': 3,
  'n_neighbors': 3,
  'neighbors_algorithm': 'kd_tree',
})
Incumbent score ...
0.03707106781186553
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 670869 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 8f6286 and rejected config 670869 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 7a96f4 and rejected config 8f6286 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 772003 and rejected config 7a96f4 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 3,
})
Incumbent score ...
0.639857679763058
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c04d5b as new incumbent because there are no incumbents yet.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'amg',
  'n_components': 2,
})
Incumbent score ...
0.4673869850679817
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config eddb2d and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][abstract_intensifier.py:590] Added config 15b947 and rejected config eddb2d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config e4265e and rejected config 15b947 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'correlation',
  'min_dist': 0.1713437177933631,
  'n_components': 2,
  'n_neighbors': 38,
})
Incumbent score ...
0.45360827445983887
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
         optimized_method  ...                                          incumbent
0  Local_Linear_Embedding  ...  {'eigen_solver': 'dense', 'method': 'modified'...

[1 rows x 3 columns]
Local_Linear_Embedding
{'eigen_solver': 'dense', 'method': 'modified', 'n_components': 3, 'n_neighbors': 3, 'neighbors_algorithm': 'kd_tree'}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
Local_Linear_Embedding
Initiating Consensus Clustering...
Local_Linear_Embedding
Initiating Consensus Clustering...
Local_Linear_Embedding
Mean score from Consensus Clustering is...
0.03707106781186553
Starting runs for the following method: PCA_sklearn
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 8621bf as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 055ddd and rejected config 8621bf as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config bb1ddd and rejected config 055ddd as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config f9e50c and rejected config bb1ddd as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 2,
  'n_oversamples': 10,
  'power_iteration_normalizer': 'auto',
  'svd_solver': 'randomized',
})
Incumbent score ...
0.6486379332817087
Starting runs for the following method: Truncated_SVD
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 6ee9d6 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config ceeea4 and rejected config 6ee9d6 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 95982d and rejected config ceeea4 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 221aeb and rejected config 95982d as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 02910c and rejected config 221aeb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config a7c812 and rejected config 02910c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 83c416 and rejected config a7c812 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 7b2d30 and rejected config 83c416 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'n_components': 2,
  'n_iter': 5,
  'n_oversamples': 3,
  'power_iteration_normalizer': 'auto',
})
Incumbent score ...
0.6315829776484494
Starting runs for the following method: Incremental_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config f874a2 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 3a8af1 and rejected config f874a2 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 233e3f and rejected config 3a8af1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e4a18c and rejected config 233e3f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config faa210 and rejected config e4a18c as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'batch_size': 325,
  'n_components': 8,
})
Incumbent score ...
0.7279239796907584
Starting runs for the following method: IndependentCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config fca8a8 as new incumbent because there are no incumbents yet.
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[INFO][abstract_intensifier.py:590] Added config 7594ea and rejected config fca8a8 as incumbent because it is not better than the incumbents on 3 instances:
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 876, in train
    X, X_r = IndependentCA(X_scaled, **config_dict)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 124, in IndependentCA
    W = model.fit_transform(X)
        ^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 708, in fit_transform
    return self._fit_transform(X, compute_sources=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/decomposition/_fastica.py", line 683, in _fit_transform
    self.mixing_ = linalg.pinv(self.components_, check_finite=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_basic.py", line 1326, in pinv
    u, s, vh = _decomp_svd.svd(a, full_matrices=False, check_finite=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/linalg/_decomp_svd.py", line 133, in svd
    raise ValueError('illegal value in %dth argument of internal gesdd'
ValueError: illegal value in 4th argument of internal gesdd


[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 2f72ce and rejected config 7594ea as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'algorithm': 'deflation',
  'fun': 'cube',
  'n_components': 2,
  'whiten_solver': 'svd',
})
Incumbent score ...
0.6500066272634935
Starting runs for the following method: Sparse_PCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 82e818 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config a1ac8e and rejected config 82e818 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 7a8af1 and rejected config a1ac8e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config fa4141 and rejected config 7a8af1 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config c4a0e8 and rejected config fa4141 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.7349023767684202,
  'method': 'cd',
  'n_components': 2,
  'ridge_alpha': 0.06468956798289197,
})
Incumbent score ...
0.6576414758814471
Starting runs for the following method: MiniBatch_SparsePCA
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config a0e6e3 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 5f7a42 and rejected config a0e6e3 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config a5075f and rejected config 5f7a42 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 64df9b and rejected config a5075f as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e79972 and rejected config 64df9b as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'alpha': 0.17608831181404183,
  'batch_size': 5,
  'method': 'lars',
  'n_components': 2,
  'ridge_alpha': 0.0720935512303323,
})
Incumbent score ...
0.635135041025038
Starting runs for the following method: Factor_Analysis
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config ba831f as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 16a300 and rejected config ba831f as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config 7553d7 and rejected config 16a300 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config b2d64a and rejected config 7553d7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config e15bef and rejected config b2d64a as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1417a5 and rejected config e15bef as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'iterated_power': 4,
  'n_components': 2,
  'rotation': 'varimax',
  'svd_method': 'lapack',
})
Incumbent score ...
0.6570978793604707
Starting runs for the following method: t_SNE
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config d953c7 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config fa2702 and rejected config d953c7 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 332582 and rejected config fa2702 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'angle': 0.40060205128971693,
  'early_exaggeration': 30.967104144758714,
  'init': 'random',
  'learning_rate': 223.02319640889678,
  'method': 'barnes_hut',
  'n_components': 2,
  'n_iter': 854,
  'n_iter_without_progress': 499,
  'perplexity': 41.0774538034608,
})
Incumbent score ...
0.4012727737426758
Starting runs for the following method: Iso_map
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config c1327e as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 1e6abb and rejected config c1327e as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 1c5ab6 and rejected config 1e6abb as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config ccd634 and rejected config 1c5ab6 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config d7dd38 and rejected config ccd634 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 9e597c and rejected config d7dd38 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'n_components': 2,
  'n_neighbors': 7,
  'neighbors_algorithm': 'auto',
  'path_method': 'FW',
})
Incumbent score ...
0.5156751130416962
Starting runs for the following method: Local_Linear_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 45baed as new incumbent because there are no incumbents yet.
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[WARNING][abstract_runner.py:132] Target function returned infinity or nothing at all. Result is treated as CRASHED and cost is set to inf.
[WARNING][abstract_runner.py:138] Traceback: Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 177, in null_space
    eigen_values, eigen_vectors = eigsh(
                                  ^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1651, in eigsh
    Minv_matvec = get_OPinv_matvec(A, M, sigma,
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1063, in get_OPinv_matvec
    return get_inv_matvec(A, hermitian=hermitian, tol=tol)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 1056, in get_inv_matvec
    return SpLuInv(M).matvec
           ^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py", line 915, in __init__
    self.M_lu = splu(M)
                ^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py", line 413, in splu
    return _superlu.gstrf(N, A.nnz, A.data, A.indices, A.indptr,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Factor is exactly singular

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 184, in run
    rval = self(config_copy, target_function, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/smac/runner/target_function_runner.py", line 257, in __call__
    return algorithm(config, **algorithm_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 1154, in train
    X, X_r = Local_Linear_Embedding(X_scaled, **config_dict)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/AutoMF/AutoMFOptimized2.py", line 197, in Local_Linear_Embedding
    X_hat = transformer.fit_transform(X)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 799, in fit_transform
    self._fit_transform(X)
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 746, in _fit_transform
    self.embedding_, self.reconstruction_error_ = locally_linear_embedding(
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 543, in locally_linear_embedding
    return null_space(
           ^^^^^^^^^^^
  File "/mnt/belinda_local/daniel/home/anaconda3/envs/GenerativeAI/lib/python3.11/site-packages/sklearn/manifold/_locally_linear.py", line 181, in null_space
    raise ValueError(
ValueError: Error in determining null-space with ARPACK. Error message: 'Factor is exactly singular'. Note that eigen_solver='arpack' can fail when the weight matrix is singular or otherwise ill-behaved. In that case, eigen_solver='dense' is recommended. See online documentation for more information.


[INFO][abstract_intensifier.py:590] Added config 0a5e4f and rejected config 45baed as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config f71784 and rejected config 0a5e4f as incumbent because it is not better than the incumbents on 3 instances:
method crashed, ignoring Ensemble classifier ...
method crashed, ignoring Ensemble classifier ...
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'eigen_solver': 'auto',
  'method': 'modified',
  'n_components': 6,
  'n_neighbors': 71,
  'neighbors_algorithm': 'kd_tree',
})
Incumbent score ...
0.7696153960571149
Starting runs for the following method: Multidimensional_scaling
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config f1e561 as new incumbent because there are no incumbents yet.
[INFO][abstract_intensifier.py:590] Added config 40f494 and rejected config f1e561 as incumbent because it is not better than the incumbents on 2 instances:
[INFO][abstract_intensifier.py:590] Added config e53b32 and rejected config 40f494 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config e46e22 and rejected config e53b32 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 09b985 and rejected config e46e22 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 8f6286 and rejected config 09b985 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 50 trials.
[WARNING][config_selector.py:242] Could not return a new configuration after 16 retries.
[INFO][smbo.py:332] Shutting down because the stop flag was set.
Configuration(values={
  'dissimilarity': 'euclidean',
  'n_components': 2,
  'n_init': 5,
})
Incumbent score ...
0.6968118114097868
Starting runs for the following method: Spectral_Embedding
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 444707 as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config 043181 and rejected config 444707 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'affinity': 'nearest_neighbors',
  'eigen_solver': 'lobpcg',
  'n_components': 8,
})
Incumbent score ...
0.5091074635934392
Starting runs for the following method: U_MAP
[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.
[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.
[INFO][abstract_intensifier.py:515] Added config 957b92 as new incumbent because there are no incumbents yet.
[INFO][smbo.py:319] Finished 50 trials.
[INFO][abstract_intensifier.py:590] Added config ce0332 and rejected config 957b92 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config 3792db and rejected config ce0332 as incumbent because it is not better than the incumbents on 3 instances:
[INFO][abstract_intensifier.py:590] Added config cad34c and rejected config 3792db as incumbent because it is not better than the incumbents on 3 instances:
[INFO][smbo.py:319] Finished 100 trials.
[INFO][smbo.py:327] Configuration budget is exhausted:
[INFO][smbo.py:328] --- Remaining wallclock time: inf
[INFO][smbo.py:329] --- Remaining cpu time: inf
[INFO][smbo.py:330] --- Remaining trials: 0
Configuration(values={
  'metric': 'braycurtis',
  'min_dist': 0.22503306947913432,
  'n_components': 3,
  'n_neighbors': 15,
})
Incumbent score ...
0.32677823305130005
Saving method comparisons results ... 
Best optimal model found by Bayesian Optimization is...
  optimized_method     score                                          incumbent
0            U_MAP  0.326778  {'metric': 'braycurtis', 'min_dist': 0.2250330...
U_MAP
{'metric': 'braycurtis', 'min_dist': 0.22503306947913432, 'n_components': 3, 'n_neighbors': 15}
Now performing Consensus Ensamble Clustering with best optimal model...
Initiating Consensus Clustering...
U_MAP
Initiating Consensus Clustering...
U_MAP
Initiating Consensus Clustering...
U_MAP
Mean score from Consensus Clustering is...
0.32562969128290814
1327091.55user 73568.67system 18:11:17elapsed 2139%CPU (0avgtext+0avgdata 6307728maxresident)k
47752inputs+955384outputs (201major+67868574minor)pagefaults 0swaps
